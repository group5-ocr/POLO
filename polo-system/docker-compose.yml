version: "3.9"

services:
    easy-train:
      build: ./models/fine-tuning
      container_name: easy-train
      environment:
        - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
        - CUDA_VISIBLE_DEVICES=0
      command: >
        python3 training/qlora.py
        --model_name_or_path meta-llama/Llama-3.2-3B-Instruct
        --train_file /app/training/train.jsonl
        --output_dir /app/outputs/llama32-3b-qlora
        --report_to_tensorboard
        --train_fraction 0.3
        --num_train_epochs 3
        --save_every_steps 500
        --logging_steps 10
        --bf16
        --bnb_4bit
        --bnb_4bit_quant_type nf4
        --per_device_train_batch_size 1
        --gradient_accumulation_steps 4
        --max_seq_length 256
        --gradient_checkpointing
        --learning_rate 2e-4
        --warmup_ratio 0.03

      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]

      runtime: nvidia

      volumes:
        - ./models/fine-tuning:/app
        - ./models/fine-tuning/outputs:/app/outputs

  # ğŸ’¤ ë‚˜ì¤‘ì— í™œì„±í™”í•  ì„œë¹„ìŠ¤ë“¤
  # backend:
  #   build: ./server
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - ./server:/app
  #     - ./server/results:/app/results
  #   env_file:
  #     - ./server/.env
  #   command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload 

  # math-llm:
  #   build: ./models/math
  #   ports:
  #     - "5001:5001"
  #   volumes:
  #     - ./models/math:/app

  # easy-llm:
  #   build: ./models/fine-tuning
  #   ports:
  #     - "5003:5003"
  #   environment:
  #     - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
  #   volumes:
  #     - ./models/fine-tuning:/app