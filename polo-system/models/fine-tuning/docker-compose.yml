services:
  # 기존 Easy 모델 학습 (유지)
  easy-train:
    build:
      context: .
      dockerfile: dockerfile
    container_name: easy-train
    env_file:
      - .env
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_TOKEN=${HUGGINGFACE_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
    gpus: all
    working_dir: /app
    volumes:
      - .:/app
    command: >
      python training/qlora.py
      --model_name_or_path meta-llama/Llama-3.2-3B-Instruct
      --train_file training/train.jsonl
      --output_dir outputs/llama32-3b-qlora
      --report_to_tensorboard
      --train_fraction 0.6
      --num_train_epochs 10
      --save_every_steps 500
      --logging_steps 10
      --bf16
      --bnb_4bit
      --bnb_4bit_quant_type nf4
      --per_device_train_batch_size 1
      --gradient_accumulation_steps 4
      --max_seq_length 256
      --gradient_checkpointing
      --learning_rate 2e-4
      --warmup_ratio 0.03
      --resume_from_checkpoint outputs/yolo-easy-qlora\checkpoint-20
      --target_modules q_proj,k_proj,v_proj,o_proj

  # YOLO 논문 전용 학습 (새로 추가)
  yolo-train:
    build:
      context: .
      dockerfile: dockerfile
    container_name: yolo-train
    env_file:
      - .env
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_TOKEN=${HUGGINGFACE_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
    gpus: all
    working_dir: /app
    volumes:
      - .:/app
    command: >
      python training/qlora_yolo.py
      --model_name_or_path meta-llama/Llama-3.2-3B-Instruct
      --yolo_json_path training/yolo_v1.json
      --output_dir outputs/yolo-easy-qlora
      --report_to_tensorboard
      --train_fraction 1.0
      --num_train_epochs 15
      --save_every_steps 200
      --logging_steps 5
      --bf16
      --bnb_4bit
      --bnb_4bit_quant_type nf4
      --per_device_train_batch_size 1
      --gradient_accumulation_steps 4
      --max_seq_length 1024
      --gradient_checkpointing
      --learning_rate 2e-4
      --warmup_ratio 0.1
      --lora_r 16
      --lora_alpha 32
      --lora_dropout 0.05
      --target_modules q_proj,k_proj,v_proj,o_proj
      --resume_from_checkpoint outputs/yolo-easy-qlora/checkpoint-4000
      --early_stopping_patience 3
      --early_stopping_threshold 0.001
      --eval_steps 100

  # 기존 Easy 모델 서빙 (유지)
  easy-llm:
    build:
      context: .
      dockerfile: dockerfile
    container_name: easy-llm
    env_file:
      - .env
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_TOKEN=${HUGGINGFACE_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
    gpus: all
    working_dir: /app
    volumes:
      - .:/app
    ports:
      - "5003:5003"
    command: python app.py
    depends_on:
      - easy-train

  # YOLO 논문 전용 서빙 (새로 추가)
  yolo-llm:
    build:
      context: .
      dockerfile: dockerfile
    container_name: yolo-llm
    env_file:
      - .env
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_TOKEN=${HUGGINGFACE_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_TOKEN}
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
    gpus: all
    working_dir: /app
    volumes:
      - .:/app
    ports:
      - "5004:5004"
    command: python app_yolo.py
    depends_on:
      - yolo-train
