from __future__ import annotations
import os
import json
import argparse
import torch
from typing import Dict, Optional, List
from datasets import load_dataset, Dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    EarlyStoppingCallback,
    TrainerCallback,
    TrainerState,
    TrainerControl,
)
from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training
from trl import SFTTrainer, SFTConfig
from huggingface_hub import login
import re

token = os.getenv("HUGGINGFACE_TOKEN") or os.getenv("HF_TOKEN") or os.getenv("HUGGINGFACE_HUB_TOKEN")
if not token:
    raise RuntimeError("HF token not found in env vars.")
login(token=token, add_to_git_credential=True)

# =============================
# 1) ì»¤ìŠ¤í…€ Early Stopping ì½œë°±
# =============================
class CustomEarlyStoppingCallback(TrainerCallback):
    def __init__(self, 
                 target_loss: float = 0.1,
                 patience: int = 8,
                 min_delta: float = 0.001,
                 min_epochs: int = 20):
        self.target_loss = target_loss
        self.patience = patience
        self.min_delta = min_delta
        self.min_epochs = min_epochs
        self.best_loss = float('inf')
        self.wait_count = 0
        self.epoch_count = 0
        
    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):
        if logs is None:
            return
            
        current_loss = logs.get('train_loss', None)
        if current_loss is None:
            return
            
        self.epoch_count += 1
        
        # ìµœì†Œ ì—í¬í¬ ìˆ˜ í™•ì¸
        if self.epoch_count < self.min_epochs:
            print(f"ğŸ”„ [Early Stopping] ìµœì†Œ ì—í¬í¬ ìˆ˜ ë¯¸ë‹¬ ({self.epoch_count}/{self.min_epochs}) - ê³„ì† í•™ìŠµ")
            return
            
        # ëª©í‘œ ì†ì‹¤ê°’ ë‹¬ì„± í™•ì¸
        if current_loss <= self.target_loss:
            print(f"ğŸ¯ [Early Stopping] ëª©í‘œ ì†ì‹¤ê°’ ë‹¬ì„±! í˜„ì¬: {current_loss:.4f} <= ëª©í‘œ: {self.target_loss}")
            control.should_training_stop = True
            return
            
        # ê°œì„  í™•ì¸
        if current_loss < self.best_loss - self.min_delta:
            self.best_loss = current_loss
            self.wait_count = 0
            print(f"âœ… [Early Stopping] ì†ì‹¤ê°’ ê°œì„ : {current_loss:.4f} (ì´ì „ ìµœê³ : {self.best_loss:.4f})")
        else:
            self.wait_count += 1
            print(f"â³ [Early Stopping] ê°œì„  ì—†ìŒ ({self.wait_count}/{self.patience}) - í˜„ì¬: {current_loss:.4f}, ìµœê³ : {self.best_loss:.4f}")
            
        # Patience ì´ˆê³¼ ì‹œ ì¤‘ë‹¨
        if self.wait_count >= self.patience:
            print(f"ğŸ›‘ [Early Stopping] Patience ì´ˆê³¼! í•™ìŠµ ì¤‘ë‹¨ - {self.wait_count}ë²ˆ ì—°ì† ê°œì„  ì—†ìŒ")
            control.should_training_stop = True
            
    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        train_loss = state.log_history[-1].get('train_loss', 'N/A')
        if isinstance(train_loss, (int, float)):
            print(f"ğŸ“Š [Epoch {self.epoch_count}] í˜„ì¬ ì†ì‹¤: {train_loss:.4f}")
        else:
            print(f"ğŸ“Š [Epoch {self.epoch_count}] í˜„ì¬ ì†ì‹¤: {train_loss}")

# =============================
# 2) YOLO ë°ì´í„° ì „ì²˜ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ìœ í‹¸
# =============================
SYS_PROMPT = (
    "ë„ˆëŠ” AI ë…¼ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì›ë¬¸ ì˜ë¯¸ë¥¼ ìœ ì§€í•œ ì±„ í•œêµ­ì–´ë¡œ ì‰½ê²Œ í’€ì–´ì“°ëŠ” ì „ë¬¸ê°€ë‹¤.\n"
    "ê·œì¹™:\n"
    "- ì˜ë¬¸ ì „ë¬¸ìš©ì–´ëŠ” ì˜ì–´ í‘œê¸° ê·¸ëŒ€ë¡œ ë‘ê³ , ë°”ë¡œ ë’¤ì— (ì§§ì€ í•œêµ­ì–´ í’€ì´)ë¥¼ 1íšŒë§Œ ë¶™ì—¬ë¼. ê°™ì€ ë¬¸ë‹¨ì—ì„œ ë™ì¼ ìš©ì–´ëŠ” ë‹¤ì‹œ í’€ì´í•˜ì§€ ë§ˆë¼.\n"
    "- ìˆ˜ì‹/ì½”ë“œ/ë§í¬/í† í°ì€ ë³€í˜• ê¸ˆì§€. ì…ë ¥ì— âŸ¦MATH_iâŸ§, âŸ¦CODE_iâŸ§ ê°™ì€ ë§ˆìŠ¤í¬ê°€ ì˜¤ë©´ ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ê³ , ì¶œë ¥ì—ë„ ë™ì¼í•˜ê²Œ ë‚¨ê²¨ë¼.\n"
    "- ìˆ«ì/ê¸°í˜¸/ë‹¨ìœ„/ì•½ì–´ë¥¼ ë°”ê¾¸ì§€ ë§ˆë¼. ì¶”ì¸¡/ê³¼ì¥ì€ ê¸ˆì§€.\n"
    "- 3~5 ë¬¸ë‹¨, ê° 2~4ë¬¸ì¥. ë§¤ ë¬¸ë‹¨ì€ ì—°ê²°ì–´(ë¨¼ì €/ë‹¤ìŒ/ë§ˆì§€ë§‰ ë“±)ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‡ëŠ”ë‹¤.\n"
    "- ë¶ˆí•„ìš”í•œ ë°˜ë³µ/êµ°ë”ë”ê¸° ì œê±°. \"ë°©ë²•/ì½”ë”©ë°©ì‹\" ê°™ì€ ë³´ì¡°í’€ì´ë¥¼ ê³¼ë„í•˜ê²Œ ë„£ì§€ ë§ˆë¼.\n"
    "\n"
    "í˜•ì‹:\n"
    "- í•œêµ­ì–´ ë³¸ë¬¸ë§Œ ì¶œë ¥. ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§/ì„¤ëª… ê¸ˆì§€.\n"
    "\n"
    "ì£¼ì˜: âŸ¦MATH_iâŸ§, âŸ¦CODE_iâŸ§, âŸ¦URL_iâŸ§ ê°™ì€ í† í°ì€ **ê·¸ëŒ€ë¡œ** ì¶œë ¥ì— ë³µì‚¬í•˜ë¼. ë‚´ìš©/ìˆœì„œ/ê³µë°±ì„ ë°”ê¾¸ì§€ ë§ˆë¼."
)

INSTRUCT_TEMPLATE = (
    "<|begin_of_text|>\n"
    "<|start_header_id|>system<|end_header_id|>\n"
    "{sys}\n"
    "<|eot_id|>\n"
    "<|start_header_id|>user<|end_header_id|>\n"
    "[SECTION] {section_title}\n"
    "[TEXT]\n{input}\n\n[REWRITE in Korean]\n"
    "<|eot_id|>\n"
    "<|start_header_id|>assistant<|end_header_id|>\n"
    "{output}<|eot_id|>"
)

def get_section_name(section_major: int) -> str:
    """ì„¹ì…˜ ë²ˆí˜¸ë¥¼ ì„¹ì…˜ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    section_names = {
        0: "Abstract",
        1: "Introduction", 
        2: "Unified Detection",
        3: "Training",
        4: "Experiments",
        5: "Real-Time Detection",
        6: "Conclusion"
    }
    return section_names.get(section_major, f"Section {section_major}")

def clean_yolo_text(text: str) -> str:
    """YOLO ë°ì´í„°ì˜ ë°˜ë³µ ë¬¸ì¥ ì œê±°"""
    # "In simple terms, the method keeps steps minimal..." ë°˜ë³µ ì œê±°
    text = re.sub(r"In simple terms, the method keeps steps minimal, uses full-image context, and directly predicts useful numbers \(like box positions\) and labels together\.", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def preprocess_yolo_data(json_path: str) -> List[Dict]:
    """YOLO JSON ë°ì´í„°ë¥¼ Easy ëª¨ë¸ìš©ìœ¼ë¡œ ì „ì²˜ë¦¬"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    processed_data = []
    
    # ë¬¸ë‹¨ë³„ë¡œ ê·¸ë£¹í™” (ì„¹ì…˜.ì„œë¸Œì„¹ì…˜ ë‹¨ìœ„)
    paragraphs = {}
    for item in data:
        key = f"{item['section_major']}.{item['section_minor']}"
        if key not in paragraphs:
            paragraphs[key] = {
                "section_major": item['section_major'],
                "section_minor": item['section_minor'],
                "original_sentences": [],
                "simplified_sentences": []
            }
        
        # ì›ë¬¸ê³¼ ê°„ì†Œí™” ë¬¸ì¥ì„ ê°ê° ì €ì¥
        paragraphs[key]["original_sentences"].append(item["original"])
        paragraphs[key]["simplified_sentences"].append(clean_yolo_text(item["simplified"]))
    
    # ë¬¸ë‹¨ë³„ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±
    for key, para in paragraphs.items():
        section_title = get_section_name(para['section_major'])
        
        # ì›ë¬¸ê³¼ ê°„ì†Œí™” í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì¹˜ê¸°
        original_text = " ".join(para["original_sentences"])
        simplified_text = " ".join(para["simplified_sentences"])
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ìŠ¤í‚µ
        if not original_text.strip() or not simplified_text.strip():
            continue
            
        processed_data.append({
            "instruction": f"ë‹¤ìŒ {section_title} ì„¹ì…˜ì„ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
            "input": original_text,
            "output": simplified_text,
            "section_title": section_title,
            "section_major": para['section_major'],
            "section_minor": para['section_minor']
        })
    
    return processed_data

def build_text_from_row(row: Dict) -> str:
    """Easy ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    section_title = row.get("section_title", "Unknown Section")
    input_text = str(row.get("input", "")).strip()
    output_text = str(row.get("output", "")).strip()
    
    return INSTRUCT_TEMPLATE.format(
        sys=SYS_PROMPT,
        section_title=section_title,
        input=input_text,
        output=output_text
    )

# =============================
# 2) ëª¨ë¸/í† í¬ë‚˜ì´ì € ì¤€ë¹„
# =============================
def str2dtype(name: str):
    name = (name or "").lower()
    if name in ["bf16", "bfloat16"]:
        return torch.bfloat16
    if name in ["fp16", "float16", "half"]:
        return torch.float16
    if name in ["fp32", "float32"]:
        return torch.float32
    return torch.bfloat16

def build_bnb_config(load_in_4bit: bool, quant_type: str, compute_dtype: str | torch.dtype):
    if isinstance(compute_dtype, str):
        compute_dtype = str2dtype(compute_dtype)
    if not load_in_4bit:
        return None
    return BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_use_double_quant=True,
        bnb_4bit_quant_type=quant_type,
        bnb_4bit_compute_dtype=compute_dtype,
    )

def prepare_model_and_tokenizer(
    model_name_or_path: str,
    use_bf16: bool = True,
    load_in_4bit: bool = True,
    bnb_quant_type: str = "nf4",
    bnb_compute_dtype: str = "bfloat16",
    gradient_checkpointing: bool = True,
):
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "right"

    quant_config = build_bnb_config(
        load_in_4bit=load_in_4bit,
        quant_type=bnb_quant_type,
        compute_dtype=bnb_compute_dtype,
    )

    model = AutoModelForCausalLM.from_pretrained(
        model_name_or_path,
        device_map="auto",
        torch_dtype=torch.bfloat16 if use_bf16 else torch.float16,
        quantization_config=quant_config,
        trust_remote_code=True,
    )

    try:
        model.config.attn_implementation = "eager"
    except Exception:
        pass

    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)
    try:
        model.enable_input_require_grads()
    except Exception:
        model.get_input_embeddings().requires_grad_(True)

    if gradient_checkpointing:
        model.gradient_checkpointing_enable()
        model.config.use_cache = False

    return model, tokenizer

# =============================
# 3) ë°ì´í„°ì…‹ ë¡œë”©
# =============================
def load_yolo_dataset(yolo_json_path: str, train_fraction: float = 0.9) -> tuple[Dataset, Dataset]:
    """YOLO JSON ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  train/validationìœ¼ë¡œ ë¶„í• """
    print(f"[ë°ì´í„°] YOLO JSON ë¡œë”©: {yolo_json_path}")
    processed_data = preprocess_yolo_data(yolo_json_path)
    print(f"[ë°ì´í„°] ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê°œ ë¬¸ë‹¨")
    
    # Datasetìœ¼ë¡œ ë³€í™˜
    dataset = Dataset.from_list(processed_data)
    
    # í…ìŠ¤íŠ¸ ë³€í™˜
    dataset = dataset.map(
        lambda ex: {"text": build_text_from_row(ex)},
        remove_columns=[c for c in dataset.column_names if c != "text"]
    )
    
    # Train/Validation ë¶„í•  (ë°ì´í„°ê°€ ì ì„ ë•ŒëŠ” trainë§Œ ì‚¬ìš©)
    if len(dataset) < 10:
        print(f"[ë°ì´í„°] ë°ì´í„°ê°€ ì ì–´ì„œ train/validation ë¶„í• ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"[ë°ì´í„°] Train: {len(dataset)}ê°œ, Eval: 0ê°œ")
        return dataset, None
    
    dataset = dataset.shuffle(seed=42)
    split_idx = int(len(dataset) * train_fraction)
    
    # ìµœì†Œ 1ê°œëŠ” validationì— ë‚¨ê²¨ë‘ê¸°
    if split_idx >= len(dataset):
        split_idx = len(dataset) - 1
    
    train_dataset = dataset.select(range(split_idx))
    eval_dataset = dataset.select(range(split_idx, len(dataset)))
    
    print(f"[ë°ì´í„°] Train: {len(train_dataset)}ê°œ, Eval: {len(eval_dataset)}ê°œ")
    
    return train_dataset, eval_dataset

# =============================
# 4) í•™ìŠµ ë£¨í‹´
# =============================
def print_trainable_parameters(model):
    """í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ì¶œë ¥"""
    total, trainable = 0, 0
    for name, p in model.named_parameters():
        n = p.numel()
        total += n
        if p.requires_grad:
            trainable += n
    pct = (trainable / total * 100.0) if total else 0.0
    print(f"[íŒŒë¼ë¯¸í„°] ì „ì²´: {total:,} | í•™ìŠµê°€ëŠ¥: {trainable:,} ({pct:.2f}%)")
    
    # LoRA íŒŒë¼ë¯¸í„° ìƒì„¸ ë¶„ì„
    lora_params = 0
    for name, p in model.named_parameters():
        if p.requires_grad and ('lora' in name.lower() or 'adapter' in name.lower()):
            lora_params += p.numel()
    print(f"[LoRA] LoRA íŒŒë¼ë¯¸í„°: {lora_params:,}")

def print_model_info(model):
    """ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶œë ¥"""
    print("\n=== ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ===")
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
    print(f"í•™ìŠµ ë¹„ìœ¨: {trainable_params/total_params*100:.2f}%")
    
    # ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ë¶„ì„
    print("\n=== ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ===")
    for name, param in model.named_parameters():
        if param.requires_grad:
            print(f"{name}: {param.numel():,} ({param.shape})")

def train(args):
    dev_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "cpu"
    print(f"[CUDA] ì‚¬ìš© ë””ë°”ì´ìŠ¤: {dev_name}")
    print(f"[ë©”ëª¨ë¦¬] GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì¤€ë¹„
    model, tokenizer = prepare_model_and_tokenizer(
        args.model_name_or_path,
        use_bf16=args.bf16,
        load_in_4bit=args.bnb_4bit,
        bnb_quant_type=args.bnb_4bit_quant_type,
        bnb_compute_dtype=args.bnb_4bit_compute_dtype,
        gradient_checkpointing=args.gradient_checkpointing,
    )

    # LoRA ì„¤ì •
    default_targets = ["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]
    targets = (
        [t.strip() for t in args.target_modules.split(",") if t.strip()]
        if args.target_modules else default_targets
    )
    
    print(f"[LoRA] íƒ€ê²Ÿ ëª¨ë“ˆ: {targets}")
    print(f"[LoRA] rank={args.lora_r}, alpha={args.lora_alpha}, dropout={args.lora_dropout}")

    lora_config = LoraConfig(
        r=args.lora_r,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules=targets,
    )

    # YOLO ë°ì´í„°ì…‹ ë¡œë“œ (train/validation ë¶„í• )
    train_dataset, eval_dataset = load_yolo_dataset(args.yolo_json_path, args.train_fraction)
    print(f"[ë°ì´í„°] Train ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"[ë°ì´í„°] Eval ìƒ˜í”Œ ìˆ˜: {len(eval_dataset)}")
    print(f"[ë°ì´í„°] ì²« ë²ˆì§¸ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°:")
    print("=" * 50)
    print(train_dataset[0]["text"][:500] + "...")
    print("=" * 50)

    # í•™ìŠµ ì„¤ì •
    sft_config = SFTConfig(
        output_dir=args.output_dir,
        per_device_train_batch_size=args.per_device_train_batch_size,
        per_device_eval_batch_size=args.per_device_train_batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,
        num_train_epochs=args.num_train_epochs,
        logging_steps=args.logging_steps,
        eval_steps=args.eval_steps,
        save_steps=args.save_every_steps,
        save_total_limit=args.save_total_limit,
        bf16=args.bf16,
        fp16=not args.bf16,
        gradient_checkpointing=True,
        lr_scheduler_type=args.lr_scheduler_type,
        warmup_ratio=args.warmup_ratio,
        optim="paged_adamw_8bit",
        report_to=["tensorboard"] if args.report_to_tensorboard else [],
        logging_dir=f"{args.output_dir}/logs",
        logging_strategy="steps",
        logging_first_step=True,
        remove_unused_columns=True,
        overwrite_output_dir=False,
        max_seq_length=args.max_seq_length,
        packing=args.packing,
        evaluation_strategy="steps" if eval_dataset is not None else "no",
        eval_strategy="steps" if eval_dataset is not None else "no",
        load_best_model_at_end=eval_dataset is not None,
        metric_for_best_model="eval_loss" if eval_dataset is not None else None,
        greater_is_better=False,
    )

    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    checkpoint_path = None
    if args.resume_from_checkpoint:
        if os.path.exists(args.resume_from_checkpoint):
            checkpoint_path = args.resume_from_checkpoint
            print(f"[ì²´í¬í¬ì¸íŠ¸] ì´ì–´ì„œ í•™ìŠµ: {checkpoint_path}")
        else:
            print(f"[ê²½ê³ ] ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {args.resume_from_checkpoint}")
            print("[ì²´í¬í¬ì¸íŠ¸] ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # ì»¤ìŠ¤í…€ Early Stopping ì½œë°± ìƒì„±
    callbacks = []
    
    # ì»¤ìŠ¤í…€ Early Stopping ì½œë°± (í•­ìƒ í™œì„±í™”)
    custom_early_stopping = CustomEarlyStoppingCallback(
        target_loss=args.target_loss,
        patience=args.early_stopping_patience,
        min_delta=args.early_stopping_min_delta,
        min_epochs=args.early_stopping_min_epochs
    )
    callbacks.append(custom_early_stopping)
    
    # ê¸°ì¡´ Early Stopping ì½œë°± (eval_datasetì´ ìˆì„ ë•Œë§Œ)
    if eval_dataset is not None:
        early_stopping_callback = EarlyStoppingCallback(
            early_stopping_patience=args.early_stopping_patience,
            early_stopping_threshold=args.early_stopping_min_delta,
        )
        callbacks.append(early_stopping_callback)
        print(f"[Early Stopping] í‘œì¤€ ì½œë°± í™œì„±í™”ë¨ (patience={args.early_stopping_patience})")
    
    print(f"ğŸ¯ [Custom Early Stopping] í™œì„±í™”ë¨")
    print(f"   - ëª©í‘œ ì†ì‹¤ê°’: {args.target_loss}")
    print(f"   - Patience: {args.early_stopping_patience}")
    print(f"   - ìµœì†Œ ì—í¬í¬: {args.early_stopping_min_epochs}")
    print(f"   - ìµœì†Œ ë³€í™”ëŸ‰: {args.early_stopping_min_delta}")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        peft_config=lora_config,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        args=sft_config,
        dataset_text_field="text",
        callbacks=callbacks,
    )

    # íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥
    print_trainable_parameters(model)
    print_model_info(model)

    # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
    print("\n[ë””ë²„ê·¸] í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì²´í¬:")
    any_grad = False
    for name, p in model.named_parameters():
        if p.requires_grad:
            any_grad = True
            print(f" - âœ… {name}: {p.numel():,} parameters")
    if not any_grad:
        raise RuntimeError("âŒ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤. LoRA target_modulesë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # í•™ìŠµ ì‹œì‘
    print(f"\n[í•™ìŠµ] ì‹œì‘ - {args.num_train_epochs} epochs, {len(train_dataset)} samples")
    print(f"[í•™ìŠµ] ë°°ì¹˜ í¬ê¸°: {args.per_device_train_batch_size} Ã— {args.gradient_accumulation_steps} = {args.per_device_train_batch_size * args.gradient_accumulation_steps}")
    print(f"[í•™ìŠµ] í•™ìŠµë¥ : {args.learning_rate}")
    
    trainer.train(resume_from_checkpoint=checkpoint_path)
    
    # ëª¨ë¸ ì €ì¥
    trainer.model.save_pretrained(args.output_dir)
    tokenizer.save_pretrained(args.output_dir)
    print(f"[ì™„ë£Œ] ëª¨ë¸ ì €ì¥: {args.output_dir}")

# =============================
# 5) LoRA ë³‘í•© (ì˜µì…˜)
# =============================
def merge_adapters(args):
    if not args.adapter_path:
        raise ValueError("--adapter_path ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    base = AutoModelForCausalLM.from_pretrained(
        args.model_name_or_path,
        device_map="auto",
        torch_dtype=torch.bfloat16 if args.bf16 else torch.float16,
        trust_remote_code=True,
    )
    merged = PeftModel.from_pretrained(base, args.adapter_path).merge_and_unload()

    os.makedirs(args.merge_save_dir, exist_ok=True)
    merged.save_pretrained(args.merge_save_dir, safe_serialization=True)

    tok = AutoTokenizer.from_pretrained(args.model_name_or_path, use_fast=True)
    tok.save_pretrained(args.merge_save_dir)
    print(f"[ì™„ë£Œ] ë³‘í•© ì €ì¥: {args.merge_save_dir}")

# =============================
# 6) CLI
# =============================
def build_parser():
    p = argparse.ArgumentParser(description="YOLO ë…¼ë¬¸ Easy ëª¨ë¸ íŒŒì¸íŠœë‹")
    
    # ë°ì´í„°/ëª¨ë¸
    p.add_argument("--model_name_or_path", type=str, default="meta-llama/Llama-3.2-3B-Instruct")
    p.add_argument("--yolo_json_path", type=str, default="training/yolo_v1.json")
    p.add_argument("--output_dir", type=str, default="./outputs/yolo-easy-qlora")

    # ë¡œê¹…/ì €ì¥
    p.add_argument("--logging_steps", type=int, default=5)
    p.add_argument("--save_every_steps", type=int, default=200)
    p.add_argument("--save_total_limit", type=int, default=3)
    p.add_argument("--report_to_tensorboard", action="store_true")

    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê°œì„ ëœ ì„¤ì •)
    p.add_argument("--num_train_epochs", type=float, default=100.0)  # ë” ë§ì€ ì—í¬í¬
    p.add_argument("--per_device_train_batch_size", type=int, default=2)  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
    p.add_argument("--gradient_accumulation_steps", type=int, default=8)  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì¦ê°€
    p.add_argument("--learning_rate", type=float, default=5e-5)  # í•™ìŠµë¥  ê°ì†Œ
    p.add_argument("--lr_scheduler_type", type=str, default="cosine")
    p.add_argument("--warmup_ratio", type=float, default=0.1)
    p.add_argument("--max_seq_length", type=int, default=1024)
    p.add_argument("--packing", action="store_true")
    p.add_argument("--train_fraction", type=float, default=1.0)
    p.add_argument("--seed", type=int, default=42)
    
    # ì»¤ìŠ¤í…€ Early Stopping ì„¤ì •
    p.add_argument("--target_loss", type=float, default=0.1, help="ëª©í‘œ ì†ì‹¤ê°’ (ì´ ê°’ì— ë„ë‹¬í•˜ë©´ í•™ìŠµ ì¤‘ë‹¨)")
    p.add_argument("--early_stopping_patience", type=int, default=5, help="ê°œì„  ì—†ì´ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜")
    p.add_argument("--early_stopping_min_delta", type=float, default=0.001, help="ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ëŸ‰")
    p.add_argument("--early_stopping_min_epochs", type=int, default=10, help="ìµœì†Œ í•™ìŠµ ì—í¬í¬ ìˆ˜")
    p.add_argument("--eval_steps", type=int, default=50, help="í‰ê°€ ì£¼ê¸° (ë” ìì£¼)")

    # 4bit/ì •ë°€ë„
    p.add_argument("--bnb_4bit", action="store_true")
    p.add_argument("--bnb_4bit_quant_type", type=str, default="nf4")
    p.add_argument("--bnb_4bit_compute_dtype", type=str, default="bfloat16")
    p.add_argument("--bf16", action="store_true")
    p.add_argument("--gradient_checkpointing", action="store_true")

    # ì¬ê°œ/íƒ€ê¹ƒ/LoRA
    p.add_argument("--resume_from_checkpoint", type=str, default=None)
    p.add_argument("--lora_r", type=int, default=32)  # LoRA rank ì¦ê°€
    p.add_argument("--lora_alpha", type=int, default=64)  # LoRA alpha ì¦ê°€
    p.add_argument("--lora_dropout", type=float, default=0.05)
    p.add_argument("--target_modules", type=str, default="q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj")  # ë” ë§ì€ ëª¨ë“ˆ íƒ€ê²ŸíŒ…

    # ë³‘í•© ì˜µì…˜
    p.add_argument("--merge_adapters", action="store_true")
    p.add_argument("--adapter_path", type=str, default=None)
    p.add_argument("--merge_save_dir", type=str, default="./merged")
    
    return p

def main():
    args = build_parser().parse_args()
    if args.merge_adapters:
        merge_adapters(args)
    else:
        train(args)

if __name__ == "__main__":
    main()
