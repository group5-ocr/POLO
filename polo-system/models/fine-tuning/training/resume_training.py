#!/usr/bin/env python3
"""
YOLO Easy λ¨λΈ ν•™μµ μ¬κ° μ¤ν¬λ¦½νΈ
μ†μ‹¤κ°’μ΄ 0.1μ— κ°€κΉμ›μ§€λ©΄ μλ™μΌλ΅ ν•™μµμ„ μ¤‘λ‹¨ν•©λ‹λ‹¤.
"""

import os
import sys
import subprocess
from pathlib import Path

def main():
    # ν„μ¬ λ””λ ‰ν† λ¦¬λ¥Ό training ν΄λ”λ΅ μ„¤μ •
    training_dir = Path(__file__).parent
    os.chdir(training_dir)
    
    print("π€ YOLO Easy λ¨λΈ ν•™μµ μ¬κ° μ‹μ‘")
    print("=" * 60)
    
    # μ²΄ν¬ν¬μΈνΈ κ²½λ΅ ν™•μΈ
    checkpoint_dir = Path("../outputs/yolo-easy-qlora")
    if not checkpoint_dir.exists():
        print("β μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬κ°€ μ—†μµλ‹λ‹¤. μ²μλ¶€ν„° ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤.")
        checkpoint_path = None
    else:
        # κ°€μ¥ μµκ·Ό μ²΄ν¬ν¬μΈνΈ μ°ΎκΈ°
        checkpoints = list(checkpoint_dir.glob("checkpoint-*"))
        if checkpoints:
            latest_checkpoint = max(checkpoints, key=lambda x: int(x.name.split("-")[1]))
            checkpoint_path = str(latest_checkpoint)
            print(f"β… μµμ‹  μ²΄ν¬ν¬μΈνΈ λ°κ²¬: {latest_checkpoint.name}")
        else:
            print("β μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤. μ²μλ¶€ν„° ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤.")
            checkpoint_path = None
    
    # ν•™μµ λ…λ Ήμ–΄ κµ¬μ„±
    cmd = [
        "python", "qlora_yolo.py",
        "--model_name_or_path", "meta-llama/Llama-3.2-3B-Instruct",
        "--yolo_json_path", "yolo_v1.json",
        "--output_dir", "../outputs/yolo-easy-qlora",
        "--num_train_epochs", "100.0",
        "--per_device_train_batch_size", "2",
        "--gradient_accumulation_steps", "8",
        "--learning_rate", "5e-5",
        "--lr_scheduler_type", "cosine",
        "--warmup_ratio", "0.1",
        "--max_seq_length", "1024",
        "--train_fraction", "1.0",
        "--seed", "42",
        "--target_loss", "0.1",
        "--early_stopping_patience", "5",
        "--early_stopping_min_delta", "0.001",
        "--early_stopping_min_epochs", "10",
        "--eval_steps", "50",
        "--logging_steps", "5",
        "--save_every_steps", "200",
        "--save_total_limit", "3",
        "--lora_r", "32",
        "--lora_alpha", "64",
        "--lora_dropout", "0.05",
        "--target_modules", "q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj",
        "--bnb_4bit",
        "--bnb_4bit_quant_type", "nf4",
        "--bnb_4bit_compute_dtype", "bfloat16",
        "--bf16",
        "--gradient_checkpointing",
        "--report_to_tensorboard"
    ]
    
    # μ²΄ν¬ν¬μΈνΈκ°€ μμΌλ©΄ μ¬κ°
    if checkpoint_path:
        cmd.extend(["--resume_from_checkpoint", checkpoint_path])
        print(f"π”„ μ²΄ν¬ν¬μΈνΈμ—μ„ ν•™μµ μ¬κ°: {checkpoint_path}")
    else:
        print("π†• μ²μλ¶€ν„° ν•™μµ μ‹μ‘")
    
    print("\nπ“‹ ν•™μµ μ„¤μ •:")
    print(f"   - λ©ν‘ μ†μ‹¤κ°’: 0.1")
    print(f"   - μµλ€ μ—ν¬ν¬: 100")
    print(f"   - ν•™μµλ¥ : 5e-5")
    print(f"   - λ°°μΉ ν¬κΈ°: 2 Γ— 8 = 16")
    print(f"   - LoRA rank: 32, alpha: 64")
    print(f"   - Patience: 5 μ—ν¬ν¬")
    print(f"   - μµμ† μ—ν¬ν¬: 10")
    
    print("\nπ― Early Stopping μ΅°κ±΄:")
    print("   1. μ†μ‹¤κ°’μ΄ 0.1 μ΄ν•λ΅ λ–¨μ–΄μ§€λ©΄ μ¦‰μ‹ μ¤‘λ‹¨")
    print("   2. 5 μ—ν¬ν¬ λ™μ• κ°μ„ μ΄ μ—†μΌλ©΄ μ¤‘λ‹¨")
    print("   3. μµμ† 10 μ—ν¬ν¬λ” ν•™μµ μ§„ν–‰")
    
    print("\n" + "=" * 60)
    print("ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤...")
    print("=" * 60)
    
    try:
        # ν•™μµ μ‹¤ν–‰
        result = subprocess.run(cmd, check=True)
        print("\nβ… ν•™μµμ΄ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤!")
        
    except subprocess.CalledProcessError as e:
        print(f"\nβ ν•™μµ μ¤‘ μ¤λ¥κ°€ λ°μƒν–μµλ‹λ‹¤: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nβΉοΈ μ‚¬μ©μμ— μν•΄ ν•™μµμ΄ μ¤‘λ‹¨λμ—μµλ‹λ‹¤.")
        sys.exit(0)

if __name__ == "__main__":
    main()
