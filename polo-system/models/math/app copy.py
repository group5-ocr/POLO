# -*- coding: utf-8 -*-
"""
LaTeX ìˆ˜ì‹ í•´ì„¤ API (FastAPI)

ì‹¤í–‰ ë°©ë²•
- ê°œë°œ ëª¨ë“œ(í•« ë¦¬ë¡œë“œ): uvicorn --reload app:app
- í”„ë¡œë•ì…˜ ëª¨ë“œ(ê¶Œì¥):   uvicorn app:app

ì œê³µ ì—”ë“œí¬ì¸íŠ¸
- GET  /health
  : ì„œë²„/ëª¨ë¸ ìƒíƒœ ì ê²€ìš© ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.

- GET  /count/{file_path:path}
  : íŠ¹ì • TeX íŒŒì¼ì˜ ìˆ˜ì‹ì„ ì¶”ì¶œí•´ "ì´ ìˆ˜ì‹ ê°œìˆ˜"ì™€ "ê³ ë‚œë„(ì¤‘í•™ìƒ ì´ìƒ) ìˆ˜ì‹ ê°œìˆ˜"ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì½˜ì†”ì—ë„ ì¦‰ì‹œ ì¶œë ¥(printf)ë˜ë©°, JSONìœ¼ë¡œ ê°œìˆ˜ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

- POST /count
  : {"path": "C:\\...\\yolo.tex"} í˜•ì‹ì˜ JSONìœ¼ë¡œ ìœ„ì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

- GET  /math/{file_path:path}
  : ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰(ìˆ˜ì‹ ì¶”ì¶œ/ë¶„ë¥˜ â†’ ë¬¸ì„œ ê°œìš”(ì˜ì–´) ìƒì„± â†’ ê³ ë‚œë„ ìˆ˜ì‹ì— ëŒ€í•œ í•´ì„¤(ì˜ì–´) ìƒì„± â†’ JSON/TeX ì €ì¥)

- POST /math
  : {"path": "C:\\...\\yolo.tex"} í˜•ì‹ì˜ JSONìœ¼ë¡œ ìœ„ì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ì˜/íŠ¹ì§•
- ì½˜ì†” ì¶œë ¥ì´ ì§€ì—°ë˜ì§€ ì•Šë„ë¡ stdout ë¼ì¸ ë²„í¼ë§ + print(..., flush=True)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì¼ë¶€ ëª¨ë¸ì—ì„œ pad_tokenê³¼ eos_tokenì´ ê°™ì„ ë•Œ ëœ¨ëŠ” ê²½ê³ ë¥¼ í”¼í•˜ê¸° ìœ„í•´,
  pad í† í°ì´ ì—†ê±°ë‚˜ eosì™€ ê°™ìœ¼ë©´ [PAD] í† í°ì„ ì¶”ê°€í•˜ê³ , generate ì‹œ attention_maskë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
- LLM í”„ë¡¬í”„íŠ¸(ë¬¸ì„œ ê°œìš”/ìˆ˜ì‹ í•´ì„¤)ëŠ” ìš”ì²­ì— ë”°ë¼ ì˜ì–´ë¡œ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
"""

# === ì…€ 1: í™˜ê²½ ì¤€ë¹„ & ëª¨ë¸ ë¡œë“œ ===
import os, sys, json, re, textwrap, datetime, torch
from typing import List, Dict
from pathlib import Path
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

# [ê¶Œì¥] ì½˜ì†” ì¶œë ¥ì´ ë°”ë¡œ ë³´ì´ë„ë¡ stdoutì„ ì¤„ ë‹¨ìœ„ë¡œ ë²„í¼ë§í•©ë‹ˆë‹¤.
# ì¼ë¶€ Windows + uvicorn --reload í™˜ê²½ì—ì„œ print ì¶œë ¥ì´ ëŠ¦ê²Œ ë³´ì´ëŠ” ë¬¸ì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤.
try:
    sys.stdout.reconfigure(line_buffering=True)
except Exception:
    pass

VERSION = "POLO-Math-API v4 (EN-prompts + flush + mask + pad)"
print(VERSION, flush=True)

# ----- ê²½ë¡œ ì„¤ì • -----
# INPUT_TEX_PATH: ê¸°ë³¸ ì˜ˆì‹œ ê²½ë¡œ (ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë³„ë„ë¡œ íŒŒì¼ ê²½ë¡œë¥¼ ë„˜ê¸°ëŠ” ê²½ìš° ì´ ê°’ì€ ì‚¬ìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
INPUT_TEX_PATH = r"C:\\POLO\\polo-system\\models\\math\\yolo.tex"
# OUT_DIR: ì‚°ì¶œë¬¼ ì €ì¥ í´ë”(JSON/TeX). ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
OUT_DIR        = "C:/POLO/polo-system/models/math/_build"
os.makedirs(OUT_DIR, exist_ok=True)

# ----- ëª¨ë¸/í† í¬ë‚˜ì´ì € ì„¤ì • -----
# MODEL_ID: ì‚¬ìš©í•  í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì´ë¦„(Qwen ìˆ˜í•™ íŠ¹í™” ì§€ì‹œí˜• ëª¨ë¸).
# USE_4BIT: VRAM ì ˆì•½ ëª©ì ì˜ 4bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€(í•„ìš” ì‹œ Trueë¡œ ì„¤ì •).
# DEVICE: CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ 'cuda', ì•„ë‹ˆë©´ 'cpu'.
MODEL_ID = "Qwen/Qwen2.5-Math-1.5B-Instruct"
USE_4BIT = False
DEVICE   = "cuda" if torch.cuda.is_available() else "cpu"

# í˜„ì¬ íŒŒì´ì¬/íŒŒì´í† ì¹˜/ì¥ì¹˜ ìƒíƒœë¥¼ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤(ë””ë²„ê¹… í¸ì˜).
print(f"Python: {sys.version.split()[0]}", flush=True)
print(f"PyTorch: {torch.__version__}", flush=True)
print(f"CUDA available: {torch.cuda.is_available()}", flush=True)
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}", flush=True)
print(f"Device selected: {DEVICE}", flush=True)

try:
    # 1) í† í¬ë‚˜ì´ì € ë¡œë“œ
    #    trust_remote_code=TrueëŠ” ëª¨ë¸ ì €ì¥ì†Œì˜ ì»¤ìŠ¤í…€ ì½”ë“œë¥¼ ì‹ ë¢°í•˜ê³  ë¡œë“œí•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)

    # 2) pad í† í° ë³´ì •
    #    - ì¼ë¶€ ëª¨ë¸ì€ pad_tokenì´ ì—†ê±°ë‚˜ eos_tokenê³¼ ê°™ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    #    - ì´ëŸ° ê²½ìš° attention_mask ìë™ ìƒì„±ì´ ëª¨í˜¸í•˜ì—¬ ê²½ê³ /ì˜¤ë™ì‘ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    #      [PAD]ë¥¼ ì¶”ê°€í•˜ì—¬ pad_token_idë¥¼ ëª…í™•íˆ ë§Œë“­ë‹ˆë‹¤.
    PAD_ADDED = False
    if tokenizer.pad_token_id is None or tokenizer.pad_token_id == tokenizer.eos_token_id:
        tokenizer.add_special_tokens({'pad_token': '[PAD]'})
        PAD_ADDED = True

    # 3) ëª¨ë¸ ë¡œë“œ (í•„ìš” ì‹œ 4bit ì–‘ìí™” ì„¤ì •)
    bnb_config = None
    if USE_4BIT:
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_use_double_quant=True,
            bnb_4bit_compute_dtype=torch.float16
        )

    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        device_map="auto",  # ê°€ìš© ì¥ì¹˜ì— ìë™ ë§¤í•‘
        torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32,
        quantization_config=bnb_config,
        low_cpu_mem_usage=True,
        trust_remote_code=True
    )

    # 4) pad í† í°ì„ ì¶”ê°€í–ˆë‹¤ë©´ ì„ë² ë”© í…Œì´ë¸” í¬ê¸° ë¦¬ì‚¬ì´ì¦ˆê°€ í•„ìš”í•©ë‹ˆë‹¤.
    if PAD_ADDED:
        model.resize_token_embeddings(len(tokenizer))

    # 5) í…ìŠ¤íŠ¸ ìƒì„± ì‹œ ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°(í•„ìš” ì‹œ ì¡°ì ˆ)
    GEN_KW = dict(
        max_new_tokens=512,  # ìƒì„± ìµœëŒ€ í† í° ìˆ˜
        temperature=0.2,     # ìƒ˜í”Œë§ ì˜¨ë„(ë‚®ì„ìˆ˜ë¡ ê²°ì •ì )
        top_p=0.9,           # ëˆ„ì  í™•ë¥  ìƒìœ„ pë§Œ ìƒ˜í”Œë§
        do_sample=True       # ìƒ˜í”Œë§ ì‚¬ìš©(ì˜¨ë„/íƒ‘P ì ìš©)
    )
    print("Model & tokenizer loaded.", flush=True)

except Exception as e:
    # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì´í›„ ìš”ì²­ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ë„ë¡ None ì²˜ë¦¬
    tokenizer = None
    model = None
    GEN_KW = {}
    print("[Model Load Error]", e, flush=True)


# === ê³µí†µ ìœ í‹¸: ë¼ì¸ ì˜¤í”„ì…‹ ì¸ë±ìŠ¤ ===
def make_line_offsets(text: str) -> List[int]:
    """
    ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬, ê° ì¤„ì˜ ì‹œì‘ ì¸ë±ìŠ¤(ì˜¤í”„ì…‹)ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
    ì¶”í›„ íŠ¹ì • ë¬¸ì ìœ„ì¹˜(index)ë¥¼ 'ëª‡ ë²ˆì§¸ ì¤„'ì¸ì§€ ë¹ ë¥´ê²Œ ì—­ë§¤í•‘í•˜ëŠ” ë° ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    lines = text.splitlines()
    offsets, pos = [], 0
    for ln in lines:
        offsets.append(pos)
        pos += len(ln) + 1  # ì¤„ë°”ê¿ˆ ë¬¸ì('\n') ê³ ë ¤
    return offsets

def build_pos_to_line(offsets: List[int]):
    """
    ë¬¸ì ìœ„ì¹˜ p(0-based index)ë¥¼ ë°›ì•„ 1-based ë¼ì¸ ë²ˆí˜¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì´ì§„ íƒìƒ‰ì„ ì‚¬ìš©í•´ ë¹ ë¥´ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    def pos_to_line(p: int) -> int:
        lo, hi = 0, len(offsets)-1
        while lo <= hi:
            mid = (lo+hi)//2
            if offsets[mid] <= p:
                lo = mid + 1
            else:
                hi = mid - 1
        return hi + 1  # 1-based
    return pos_to_line


# === ì…€ 2: LaTeX ìˆ˜ì‹ ì¶”ì¶œ ===
def extract_equations(tex: str, pos_to_line) -> List[Dict]:
    """
    LaTeX ì†ŒìŠ¤ ë¬¸ìì—´ì—ì„œ ë‹¤ì–‘í•œ ìˆ˜ì‹ í‘œê¸°ë“¤ì„ íƒì§€í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤.
    - $$ ... $$, \[ ... \], \( ... \), inline $ ... $, ê·¸ë¦¬ê³  ìˆ˜ì‹ í™˜ê²½(equation, align ë“±)
    - ê° ìˆ˜ì‹ì— ëŒ€í•´ ì‹œì‘/ë ì¸ë±ìŠ¤, ë¼ì¸ ë²ˆí˜¸, ì›ë¬¸(body) ë“±ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
    - ì¤‘ë³µ(ë™ì¼ ë²”ìœ„) ê²°ê³¼ëŠ” ì œê±°í•˜ê³ , ë¬¸ì„œ ë‚´ ë“±ì¥ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    matches: List[Dict] = []

    def add(kind, start, end, body, env=""):
        matches.append({
            "kind": kind, "env": env, "start": start, "end": end,
            "line_start": pos_to_line(start), "line_end": pos_to_line(end),
            "body": body.strip()
        })

    # $$ ... $$ ë””ìŠ¤í”Œë ˆì´ ìˆ˜ì‹
    for m in re.finditer(r"\$\$(.+?)\$\$", tex, flags=re.DOTALL):
        add("display($$ $$)", m.start(), m.end(), m.group(1))

    # \[ ... \] ë””ìŠ¤í”Œë ˆì´ ìˆ˜ì‹
    for m in re.finditer(r"\\\[(.+?)\\\]", tex, flags=re.DOTALL):
        add("display(\\[ \\])", m.start(), m.end(), m.group(1))

    # \( ... \) ì¸ë¼ì¸ ìˆ˜ì‹(ë³„ë„ êµ¬ë¶„)
    for m in re.finditer(r"\\\((.+?)\\\)", tex, flags=re.DOTALL):
        add("inline(\\( \\))", m.start(), m.end(), m.group(1))

    # inline $...$ (ë‹¨, $$ ì œì™¸)
    for m in re.finditer(r"(?<!\$)\$(?!\$)(.+?)(?<!\$)\$(?!\$)", tex, flags=re.DOTALL):
        add("inline($ $)", m.start(), m.end(), m.group(1))

    # ìˆ˜ì‹ í™˜ê²½ë“¤ (equation, align, gather ë“±)
    envs = ["equation","equation*","align","align*","multline","multline*",
            "gather","gather*","flalign","flalign*","eqnarray","eqnarray*","split"]
    for env in envs:
        pattern = rf"\\begin{{{re.escape(env)}}}(.+?)\\end{{{re.escape(env)}}}"
        for m in re.finditer(pattern, tex, flags=re.DOTALL):
            add("env", m.start(), m.end(), m.group(1), env=env)

    # ë™ì¼ ë²”ìœ„ ì¤‘ë³µ ì œê±°
    uniq = {}
    for it in matches:
        key = (it["start"], it["end"])
        if key not in uniq:
            uniq[key] = it

    # ë“±ì¥ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    out = list(uniq.values())
    out.sort(key=lambda x: x["start"])
    return out


# === ì…€ 3: ë‚œì´ë„ íœ´ë¦¬ìŠ¤í‹± ì •ì˜ ===
# ì•„ë˜ íœ´ë¦¬ìŠ¤í‹±ì€ "ì¤‘í•™ìƒ ì´ìƒ" ë‚œì´ë„ë¡œ íŒë‹¨í•  ìˆ˜ì‹ì˜ íŠ¹ì§•ì„ ê°„ë‹¨íˆ ì²´í¬í•©ë‹ˆë‹¤.
# - íŠ¹ì • ìˆ˜í•™ ê¸°í˜¸/ëª…ë ¹ì–´ í¬í•¨(âˆ‘, âˆ«, ğ”¼, KL ë“±)
# - ìˆ˜ì‹ ê¸¸ì´, ì²¨ì/ìœ—ì²¨ì ê°œìˆ˜, ì¤„ë°”ê¿ˆ í¬í•¨ì—¬ë¶€ ë“±
ADV_TOKENS = [
    r"\\sum", r"\\prod", r"\\int", r"\\lim", r"\\nabla", r"\\partial",
    r"\\mathbb", r"\\mathcal", r"\\mathbf", r"\\boldsymbol",
    r"\\argmax", r"\\argmin", r"\\operatorname", r"\\mathrm\{KL\}",
    r"\\mathbb\{E\}", r"\\Pr", r"\\sigma", r"\\mu", r"\\Sigma", r"\\theta",
    r"\\frac\{[^{}]*\{[^{}]*\}[^{}]*\}",  # ì¤‘ì²© ë¶„ìˆ˜ íŒ¨í„´
    r"\\hat\{", r"\\tilde\{", r"\\bar\{", r"\\widehat\{", r"\\widetilde\{",
    r"\\sqrt\{[^{}]*\{",                  # ì¤‘ì²© ì œê³±ê·¼
    r"\\left", r"\\right",
    r"\\in", r"\\subset", r"\\forall", r"\\exists",
    r"\\cdot", r"\\times", r"\\otimes",
    r"IoU", r"\\log", r"\\exp",
    r"\\mathbb\{R\}", r"\\mathbb\{N\}", r"\\mathbb\{Z\}",
    r"\\Delta", r"\\delta", r"\\epsilon", r"\\varepsilon",
]
ADV_RE = re.compile("|".join(ADV_TOKENS))

def count_subscripts(expr: str) -> int:
    """
    ì²¨ì('_') ì‚¬ìš© íšŸìˆ˜ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ì…‰ë‹ˆë‹¤.
    '{' ë˜ëŠ” '\' ë‹¤ìŒì— ì˜¤ëŠ” '_'ë„ ê°ì•ˆí•˜ê¸° ìœ„í•´ ë‹¨ìˆœí•œ ì •ê·œì‹ìœ¼ë¡œ ì„¸ì–´ ì¤ë‹ˆë‹¤.
    """
    return len(re.findall(r"_[a-zA-Z0-9{\\]", expr))

def is_advanced(eq: str) -> bool:
    """
    ìˆ˜ì‹ ë¬¸ìì—´ eqê°€ ê³ ë‚œë„(ì¤‘í•™ìƒ ì´ìƒ)ì¸ì§€ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.
    - ADV_RE í‚¤ì›Œë“œ ì¡´ì¬
    - ê¸¸ì´ê°€ ê¸¸ê³  ì²¨ìê°€ ì¼ì • ê°œìˆ˜ ì´ìƒ
    - ì—¬ëŸ¬ ì¤„ ìˆ˜ì‹(ì¤„ë°”ê¿ˆ í¬í•¨) + ì¼ì • ê¸¸ì´ ì´ìƒ
    """
    if ADV_RE.search(eq):
        return True
    if len(eq) > 40 and count_subscripts(eq) >= 2:
        return True
    if "\n" in eq and len(eq) > 30:
        return True
    return False


# === ì…€ 4: ë¬¸ì„œ ê°œìš”(Overview) LLM ìƒì„± ===
def take_slices(text: str, head_chars=4000, mid_chars=2000, tail_chars=4000):
    """
    ê¸´ LaTeX ë¬¸ì„œ ì „ì²´ë¥¼ ëª¨ë‘ ëª¨ë¸ì— ë„£ê¸° ì–´ë µê¸° ë•Œë¬¸ì—,
    ì•/ì¤‘/ë’¤ ì¼ë¶€ë§Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ìš”ì•½ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    - head: ë¬¸ì„œ ì•ë¶€ë¶„
    - mid : ë¬¸ì„œ ì¤‘ê°„ì˜ ì¤‘ê°„(Middle ì¤‘ì‹¬)
    - tail: ë¬¸ì„œ ëë¶€ë¶„
    """
    n = len(text)
    head = text[:min(head_chars, n)]
    mid_start = max((n // 2) - (mid_chars // 2), 0)
    mid = text[mid_start: mid_start + min(mid_chars, n)]
    tail = text[max(0, n - tail_chars):]
    return head, mid, tail

def _generate_with_mask_from_messages(messages: List[Dict]) -> str:
    """
    Qwen ì§€ì‹œí˜• í¬ë§·ì— ë§ì¶° chat í…œí”Œë¦¿ì„ ì ìš©í•©ë‹ˆë‹¤.
    - padding=Trueë¡œ íŒ¨ë”©ì„ ê°•ì œí•˜ê³ ,
    - attention_maskë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ generateì— ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
      (pad==eos ê²½ê³  ë° ë¹„ì¼ê´€ ë™ì‘ ë°©ì§€)
    """
    inputs = tokenizer.apply_chat_template(
        messages, add_generation_prompt=True, return_tensors="pt", padding=True
    )
    attention_mask = (inputs != tokenizer.pad_token_id).long()
    with torch.no_grad():
        out = model.generate(
            input_ids=inputs.to(model.device),
            attention_mask=attention_mask.to(model.device),
            **GEN_KW
        )
    return tokenizer.decode(out[0], skip_special_tokens=True)

def chat_overview(prompt: str) -> str:
    """
    ë¬¸ì„œ ì•/ì¤‘/ë’¤ ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì…ë ¥ ë°›ì•„, ì˜ì–´ë¡œ ê°„ê²°í•œ ë¬¸ì„œ ê°œìš”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - system: ê¸°ìˆ  ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ì˜ ê°„ê²°/ëª…í™• ìš”ì•½ì ì—­í•  ë¶€ì—¬
    - user  : ì‹¤ì œ í”„ë¡¬í”„íŠ¸(ì˜ì–´)
    """
    if tokenizer is None or model is None:
        raise RuntimeError("Model is not loaded.")
    messages = [
        {"role": "system", "content":
         "You are a clear, concise technical writer who summarizes LaTeX-based AI papers for a general technical audience."},
        {"role": "user", "content": prompt}
    ]
    text = _generate_with_mask_from_messages(messages)
    # ëª¨ë¸ ì¶œë ¥ì—ì„œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì´í›„ ë¶€ë¶„ë§Œ ì˜ë¼ ë°˜í™˜
    return text.split(messages[-1]["content"])[-1].strip()


# === ì…€ 5: ìˆ˜ì‹ í•´ì„¤(Explanation) LLM ìƒì„± ===
# ì‹œìŠ¤í…œ/í…œí”Œë¦¿ì€ ì˜ì–´ë¡œ ìœ ì§€(ìš”ì²­ì‚¬í•­). ì˜ˆì‹œ/ì„¤ëª…/ê²°ë¡  ìˆœì„œë¡œ ì„¤ëª…í•˜ê²Œ í•©ë‹ˆë‹¤.
EXPLAIN_SYSTEM = (
    "You are a teacher who explains math/AI research equations in clear, simple English. "
    "Always be precise, polite, and easy to understand."
)
EXPLAIN_TEMPLATE = """Please explain the following equation so that it can be understood by someone at least at a middle school level.
Follow this exact order in your output: Example â†’ Explanation â†’ Conclusion

- Example: Show the equation exactly as LaTeX in a single block (do not modify or add anything).
- Explanation: Provide bullet points explaining the meaning of symbols (âˆ‘, ğŸ™, ^, _, âˆš, \\, etc.) and the role of each term, in a clear and concise way.
- Conclusion: Summarize in one sentence the core purpose of this equation in the context of the paper (e.g., loss composition, normalization, coordinate error, probability/log-likelihood, etc.).
- (Important) Do not change the symbols or the order of the equation, and do not invent new symbols.
- (Important) Write only in English.

[Equation]
{EQUATION}
"""

def explain_equation_with_llm(eq_latex: str) -> str:
    """
    ë‹¨ì¼ ìˆ˜ì‹(LaTeX ë¬¸ìì—´)ì— ëŒ€í•´ ì˜ì–´ í•´ì„¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - system: ì„¤ëª…ì ì—­í•  ì§€ì‹œ
    - user  : í…œí”Œë¦¿ + ì‹¤ì œ ìˆ˜ì‹ ì‚½ì…
    """
    if tokenizer is None or model is None:
        raise RuntimeError("Model is not loaded.")
    messages = [
        {"role": "system", "content": EXPLAIN_SYSTEM},
        {"role": "user",   "content": EXPLAIN_TEMPLATE.format(EQUATION=eq_latex)}
    ]
    text = _generate_with_mask_from_messages(messages)
    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì´í›„ ë¶€ë¶„ë§Œ ë°˜í™˜
    return text.split(messages[-1]["content"])[-1].strip()


# === ì…€ 6: LaTeX ë¦¬í¬íŠ¸(.tex) ìƒì„± ===
def latex_escape_verbatim(s: str) -> str:
    """
    LaTeXì—ì„œ ì˜ë¯¸ ìˆëŠ” íŠ¹ìˆ˜ë¬¸ìë“¤ì„ ì´ìŠ¤ì¼€ì´í”„í•©ë‹ˆë‹¤.
    - ë¦¬í¬íŠ¸ì— ì›ë¬¸ í…ìŠ¤íŠ¸(ê°œìš” ë“±)ë¥¼ ì•ˆì „í•˜ê²Œ ì‚½ì…í•˜ê¸° ìœ„í•œ ìœ í‹¸ì…ë‹ˆë‹¤.
    """
    s = s.replace("\\", r"\\")
    s = s.replace("#", r"\#").replace("$", r"\$")
    s = s.replace("%", r"\%").replace("&", r"\&")
    s = s.replace("_", r"\_").replace("{", r"\{").replace("}", r"\}")
    s = s.replace("^", r"\^{}").replace("~", r"\~{}")
    return s

def build_report(overview: str, items: List[Dict]) -> str:
    """
    ìµœì¢… LaTeX ë¦¬í¬íŠ¸(.tex) ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    - ê°œìš”(Overview) ì„¹ì…˜ 1ê°œ
    - ê° ìˆ˜ì‹ í•´ì„¤ ì„¹ì…˜(ë¼ì¸/ì¢…ë¥˜/í™˜ê²½ í‘œê¸° + ëª¨ë¸ ì¶œë ¥ í…ìŠ¤íŠ¸)
    """
    header = (r"""\\documentclass[11pt]{article}
\\usepackage[margin=1in]{geometry}
\\usepackage{amsmath, amssymb, amsfonts}
\\usepackage{hyperref}
\\usepackage{kotex}
\\setlength{\\parskip}{6pt}
\\setlength{\\parindent}{0pt}
\\title{LaTeX Equation Explanation Report (Middle-School Level+)}
\\author{Automatic Pipeline}
\\date{""" + datetime.date.today().isoformat() + r"""}
\\begin{document}
\\maketitle
\\tableofcontents
\\newpage
""")
    parts = [header]
    parts.append(r"\\section*{Document Overview}")
    parts.append(latex_escape_verbatim(overview))
    parts.append("\n\\newpage\n")

    for it in items:
        title = f"Lines {it['line_start']}â€“{it['line_end']} / {it['kind']} {('['+it['env']+']') if it['env'] else ''}"
        parts.append(f"\\section*{{{latex_escape_verbatim(title)}}}")
        # í•´ì„¤ì€ ì´ë¯¸ LaTeXì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸(ì˜ì–´)ì¼ ê°€ëŠ¥ì„±ì´ í¬ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚½ì…
        parts.append(it["explanation"])
        parts.append("\n")

    parts.append("\\end{document}\n")
    return "\n".join(parts)


# === ë³´ì¡°: ìˆ˜ì‹ ê°œìˆ˜ë§Œ ë¹ ë¥´ê²Œ ì„¸ê¸° ===
def count_equations_only(input_tex_path: str) -> Dict[str, int]:
    """
    íŒŒì¼ì„ ì½ì–´ ìˆ˜ì‹ì„ ì¶”ì¶œí•˜ê³ , ê³ ë‚œë„ ìˆ˜ì‹ ë¶„ë¥˜ê¹Œì§€ ìˆ˜í–‰í•˜ì—¬ ê°œìˆ˜ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ì½˜ì†”ì—ë„ í•©ê³„ë¥¼ ì¦‰ì‹œ ì¶œë ¥í•©ë‹ˆë‹¤(ë””ë²„ê¹…/í™•ì¸ í¸ì˜).
    """
    p = Path(input_tex_path)
    if not p.exists():
        raise FileNotFoundError(f"Cannot find TeX file: {input_tex_path}")

    src = p.read_text(encoding="utf-8", errors="ignore")
    offsets = make_line_offsets(src)
    pos_to_line = build_pos_to_line(offsets)
    equations_all = extract_equations(src, pos_to_line)
    equations_advanced = [e for e in equations_all if is_advanced(e["body"])]

    print(f"ì´ ìˆ˜ì‹: {len(equations_all)}", flush=True)
    print(f"ì¤‘í•™ìƒ ìˆ˜ì¤€ ì´ìƒ: {len(equations_advanced)} / {len(equations_all)}", flush=True)

    return {"ì´ ìˆ˜ì‹": len(equations_all),
            "ì¤‘í•™ìƒ ìˆ˜ì¤€ ì´ìƒ": len(equations_advanced)}


# === ë©”ì¸ íŒŒì´í”„ë¼ì¸ ===
def run_pipeline(input_tex_path: str) -> Dict:
    """
    ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
    1) íŒŒì¼ ì½ê¸°
    2) ìˆ˜ì‹ ì¶”ì¶œ ë° ê³ ë‚œë„ ë¶„ë¥˜
    3) ë¬¸ì„œ ê°œìš”(ì˜ì–´) ìƒì„±
    4) ê³ ë‚œë„ ìˆ˜ì‹ ê°ê°ì— ëŒ€í•œ í•´ì„¤(ì˜ì–´) ìƒì„±
    5) JSON/TeX ì‚°ì¶œë¬¼ ì €ì¥
    6) ì²˜ë¦¬ ìš”ì•½(ê°œìˆ˜/ê²½ë¡œ) ë°˜í™˜
    """
    p = Path(input_tex_path)
    if not p.exists():
        raise FileNotFoundError(f"Cannot find TeX file: {input_tex_path}")

    # ì‚°ì¶œ í´ë” ë³´ì¥
    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)

    # 1) íŒŒì¼ ì½ê¸°
    src = p.read_text(encoding="utf-8", errors="ignore")

    # 2) ë¼ì¸ ì˜¤í”„ì…‹ ì¤€ë¹„
    offsets = make_line_offsets(src)
    pos_to_line = build_pos_to_line(offsets)

    # 3) ìˆ˜ì‹ ì¶”ì¶œ & ê³ ë‚œë„ ë¶„ë¥˜
    equations_all = extract_equations(src, pos_to_line)
    equations_advanced = [e for e in equations_all if is_advanced(e["body"])]

    # ì½˜ì†”ì— í•©ê³„ ì¦‰ì‹œ ì¶œë ¥
    print(f"ì´ ìˆ˜ì‹: {len(equations_all)}", flush=True)
    print(f"ì¤‘í•™ìƒ ìˆ˜ì¤€ ì´ìƒ: {len(equations_advanced)} / {len(equations_all)}", flush=True)

    # 4) ë¬¸ì„œ ê°œìš” ìƒì„±(ì˜ì–´ í”„ë¡¬í”„íŠ¸)
    head, mid, tail = take_slices(src)
    overview_prompt = textwrap.dedent(f"""
    You will be given three slices of a LaTeX document (head / middle / tail).
    Please produce a concise English overview with:
    - One short paragraph describing the core topic and objective of the paper.
    - A few bullet points listing the main sections or ideas (if discernible).
    - Focus on how mathematical notation and symbols are used to support the overall flow.

    [HEAD]
    {head}

    [MIDDLE]
    {mid}

    [TAIL]
    {tail}
    """).strip()
    doc_overview = chat_overview(overview_prompt)

    # 5) ê³ ë‚œë„ ìˆ˜ì‹ í•´ì„¤(ì˜ì–´) ìƒì„±
    explanations: List[Dict] = []
    for idx, item in enumerate(equations_advanced, start=1):
        print(f"[{idx}/{len(equations_advanced)}] ë¼ì¸ {item['line_start']}â€“{item['line_end']}", flush=True)
        exp = explain_equation_with_llm(item["body"])
        explanations.append({
            "index": idx,
            "line_start": item["line_start"],
            "line_end": item["line_end"],
            "kind": item["kind"],
            "env": item["env"],
            "equation": item["body"],
            "explanation": exp
        })

    # 6) JSON ì €ì¥
    json_path = os.path.join(OUT_DIR, "equations_explained.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({"overview": doc_overview, "items": explanations}, f, ensure_ascii=False, indent=2)
    print(f"ì €ì¥ëœ JSON: {json_path}", flush=True)

    # 7) LaTeX ë¦¬í¬íŠ¸(.tex) ì €ì¥
    report_tex_path = os.path.join(OUT_DIR, "yolo_math_report.tex")
    report_tex = build_report(doc_overview, explanations)
    Path(report_tex_path).write_text(report_tex, encoding="utf-8")
    print(f"ì €ì¥ëœ TeX: {report_tex_path}", flush=True)

    # 8) ì²˜ë¦¬ ìš”ì•½ ë°˜í™˜(ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ)
    return {
        "input": str(p),
        "counts": {
            "ì´ ìˆ˜ì‹": len(equations_all),
            "ì¤‘í•™ìƒ ìˆ˜ì¤€ ì´ìƒ": len(equations_advanced)
        },
        "outputs": {
            "json": json_path,
            "report_tex": report_tex_path,
            "out_dir": OUT_DIR
        }
    }


# === FastAPI ì•± ì •ì˜ ===
app = FastAPI(title="POLO Math Explainer API", version="1.0.0")

# ìš”ì²­ ë°”ë”” ìœ íš¨ì„± ê²€ì‚¬ìš© ëª¨ë¸
class MathRequest(BaseModel):
    path: str

@app.get("/health")
async def health():
    """
    ì„œë²„ ìƒíƒœ/í™˜ê²½ ì ê²€ìš© ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    - íŒŒì´ì¬/íŒŒì´í† ì¹˜ ë²„ì „, CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€, ì¥ì¹˜, ëª¨ë¸ ë¡œë“œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return {
        "status": "ok",
        "python": sys.version.split()[0],
        "torch": torch.__version__,
        "cuda": torch.cuda.is_available(),
        "device": DEVICE,
        "model_loaded": (tokenizer is not None and model is not None)
    }

@app.get("/count/{file_path:path}")
async def count_get(file_path: str):
    """
    ê²½ë¡œë¥¼ URL pathë¡œ ë„˜ê²¨ ìˆ˜ì‹ ê°œìˆ˜ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
    - íŒŒì¼ì´ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê·¸ ì™¸ ì˜ˆì™¸ëŠ” 500ìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        return count_equations_only(file_path)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")

@app.post("/count")
async def count_post(req: MathRequest):
    """
    JSON ë°”ë”” {"path": "..."}ë¡œ ìˆ˜ì‹ ê°œìˆ˜ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
    - íŒŒì¼ì´ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê·¸ ì™¸ ì˜ˆì™¸ëŠ” 500ìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        return count_equations_only(req.path)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")

@app.get("/math/{file_path:path}")
async def math_get(file_path: str):
    """
    ê²½ë¡œë¥¼ URL pathë¡œ ë„˜ê²¨ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - íŒŒì¼ì´ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê·¸ ì™¸ ì˜ˆì™¸ëŠ” 500ìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        return run_pipeline(file_path)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")

@app.post("/math")
async def math_post(req: MathRequest):
    """
    JSON ë°”ë”” {"path": "..."}ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - íŒŒì¼ì´ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê·¸ ì™¸ ì˜ˆì™¸ëŠ” 500ìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        return run_pipeline(req.path)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")

# ì§ì ‘ ì‹¤í–‰ ì§„ì…ì  (python app.py)
if __name__ == "__main__":
    import uvicorn
    # --reloadëŠ” ê°œë°œ í¸ì˜ìš©(ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘). ë°°í¬ ì‹œì—ëŠ” ì œê±°í•˜ì„¸ìš”.
    uvicorn.run("app:app", host="127.0.0.1", port=8000, reload=True)
