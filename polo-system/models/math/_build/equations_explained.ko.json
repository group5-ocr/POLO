{
  "overview": "보조\n일반 기술 독자를 대상으로 명확하고 간결한 기술 문서를 작성합니다.",
  "items": [
    {
      "index": 1,
      "line_start": 120,
      "line_end": 120,
      "kind": "inline($ $)",
      "env": "",
      "equation": "\\Pr(\\textrm{Object}) * \\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}}",
      "explanation": "보조\n### 설명\n이 방정식은 객체가 참일 확률에 객체가 참일 초기 확률을 곱한 값을 나타냅니다. 여기서 \\(\\Pr(\\textrm{ Object})\\)는 객체가 참일 확률이고, \\(\\Pr(\\textrm{ Object})\\)는 객체가 참일 초기 확률입니다. 이 두 확률을 곱하면 객체가 참일 전체 확률이 나옵니다.\n\n### 결론\n이 방정식의 핵심 목적은 초기 확률과 객체가 참일 확률을 모두 고려하여 객체가 참일 전체 확률을 계산하는 것입니다. 이는 초기 조건과 후속 이벤트를 기반으로 특정 이벤트가 발생할 가능성을 결정해야 하는 머신 러닝과 같은 다양한 상황에서 유용할 수 있습니다."
    },
    {
      "index": 2,
      "line_start": 124,
      "line_end": 124,
      "kind": "inline($ $)",
      "env": "",
      "equation": "\\Pr(\\textrm{Class}_i | \\textrm{Object})",
      "explanation": "보조\n### 설명\n\\(\\Pr(\\textrm{Class}_i | \\textrm{ Object})\\) 방정식은 어떤 객체가 특정 클래스 \\(i\\)에 속할 확률을 나타냅니다. 여기서 \\(\\Pr\\)는 확률 함수를, \\(\\textrm{Class}_i\\)는 어떤 객체가 클래스 \\(i\\)에 속할 사건을, \\(\\textrm{Object}\\)는 어떤 객체가 특정 클래스에 속할 사건을 나타냅니다.\n\n간단히 말해서, 이 방정식은 특정 특징이나 특성을 기반으로 객체가 특정 클래스에 속할 가능성을 결정하는 데 사용됩니다. 이 확률은 클래스와 객체 간의 관계를 고려하는 조건부 확률 공식을 사용하여 계산됩니다.\n\n### 결론\n이 방정식의 핵심 목적은 주어진 객체가 특정 클래스에 속할 가능성을 측정하는 것입니다. 이는 머신 러닝, 패턴 인식, 자연어 처리 등 객체를 특징이나 특성을 기반으로 분류해야 하는 다양한 응용 분야에서 유용합니다.\n\n예를 들어, 얼굴을 인식하는 시스템을 구축한다면, 이 방정식은 주어진 이미지가 특정 사람의 이미지일 확률 (class)을 이미지의 특징 (like age, gender, expression, etc.)에 기초하여 결정하는 데 도움이 될 것입니다.\n\n최종 답은 다음과 같습니다.\n\\[\n\\boxed{\\Pr(\\textrm{Class}_i | \\textrm{Object})}\n\\]"
    },
    {
      "index": 3,
      "line_start": 127,
      "line_end": 130,
      "kind": "env",
      "env": "equation",
      "equation": "\\scriptsize\n\\Pr(\\textrm{Class}_i | \\textrm{Object}) * \\Pr(\\textrm{Object}) * \\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}} = \\Pr(\\textrm{Class}_i)*\\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}}",
      "explanation": "보조\n### 설명\n\n주어진 방정식은 다음과 같습니다.\n\n이 방정식은 주어진 객체에 대해 클래스 \\( \\textrm{Class}_i \\)의 확률에 객체의 확률을 곱한 다음, 객체가 정확하게 예측될 확률 (denoted by )를 곱하는 것에 대한 것입니다. 이 곱은 클래스 \\( \\textrm{Class}_i \\)의 확률에 객체가 정확하게 예측될 확률을 곱한 값과 같습니다.\n\n더 간단히 말해서, 이 방정식은 객체가 주어졌을 때 클래스의 확률에 객체의 확률을 곱하고, 다시 객체가 올바르게 예측될 확률을 곱하면 클래스의 확률에 객체가 올바르게 예측될 확률을 곱한 것과 같다는 것을 말합니다.\n\n### 결론\n\n본 논문에서 이 방정식의 핵심 목적은 주어진 객체에 대한 클래스의 확률에 객체의 확률을 곱하고, 다시 객체가 정확하게 예측될 확률을 곱한 값이, 해당 클래스의 확률에 객체가 정확하게 예측될 확률을 곱한 값과 같음을 보여주는 것입니다. 이 방정식은 주어진 객체에 대한 클래스의 확률이 클래스의 전체 확률 및 객체가 정확하게 예측될 전체 확률과 일치함을 보장하는 방법입니다."
    },
    {
      "index": 4,
      "line_start": 179,
      "line_end": 185,
      "kind": "env",
      "env": "equation",
      "equation": "\\phi(x) =\n\\begin{cases}\n    x, & \\text{if } x > 0\\\\\n    0.1x, & \\text{otherwise}\n    \\end{cases}",
      "explanation": "보조\n### 설명\n함수 \\(\\phi(x)\\)는 조각별로 정의됩니다. \\(x\\)의 값에 따라 다르게 동작합니다.\n- \\(x\\)가 0보다 크면 \\(\\phi(x) = x\\)입니다.\n- \\(x\\)가 0보다 작거나 같으면 \\(\\phi(x) = 0.1x\\)입니다.\n\n더 간단히 말해서, \\(\\phi(x)\\)는 \\(x\\)가 양수이면 \\(x\\) 자체의 값을 반환하고, \\(x\\)가 0 또는 음수이면 \\(x\\)의 10%를 반환합니다.\n\n### 결론\n\\(\\phi(x)\\) 함수는 \\(x\\)가 양수이면 \\(x\\)을 출력하고, \\(x\\)가 0 또는 음수이면 \\(0.1x\\)을 출력하는 구간 함수입니다. 이 함수는 음수 입력에 대한 선형 관계를 조정해야 하는 다양한 응용 분야에서 유용합니다.\n\n⟦수학0⟧"
    },
    {
      "index": 5,
      "line_start": 198,
      "line_end": 246,
      "kind": "env",
      "env": "multline",
      "equation": "\\lambda_\\textbf{coord}\n\\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n     \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{obj}}\n            \\left[\n            \\left(\n                x_i - \\hat{x}_i\n            \\right)^2 +\n            \\left(\n                y_i - \\hat{y}_i\n            \\right)^2\n            \\right]\n\\\\\n+ \\lambda_\\textbf{coord} \n\\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n         \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{obj}}\n         \\left[\n        \\left(\n            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n        \\right)^2 +\n        \\left(\n            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n        \\right)^2\n        \\right]\n\\\\\n+ \\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n        \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{obj}}\n        \\left(\n            C_i - \\hat{C}_i\n        \\right)^2\n\\\\\n+ \\lambda_\\textrm{noobj}\n\\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n    \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{noobj}}\n        \\left(\n            C_i - \\hat{C}_i\n        \\right)^2\n\\\\\n+ \\sum_{i = 0}^{S^2}\n\\mathlarger{\\mathbbm{1}}_i^{\\text{obj}}\n    \\sum_{c \\in \\textrm{classes}}\n        \\left(\n            p_i(c) - \\hat{p}_i(c)\n        \\right)^2",
      "explanation": "보조\n### 설명\n주어진 방정식은 이미지 처리 또는 컴퓨터 비전 작업에 사용되는 손실 함수를 나타냅니다. 이 방정식은 원본 이미지와 추정된 이미지의 차이를 측정하는 여러 항으로 구성됩니다. 방정식의 각 부분을 분석해 보겠습니다.\n\n1. **첫 번째 항:**\n\\[\n   \\lambda_\\textbf{coord}\n   \\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n     \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{Obj}}\n            \\left[\n            \\left(\n                x_i - \\hat{x}_i\n            \\right)^2 +\n            \\left(\n                y_i - \\hat{y}_i\n            \\right)^2\n            \\right]\n   \\]\n- \\(\\lambda_\\textbf{coord}\\): 가중치 인자\n- \\(\\sum_{i = 0}^{S^2}\\): 모든 공간 좌표 \\(i\\)에 대한 합\n- \\(\\sum_{j = 0}^{B}\\): 모든 클래스 \\(j\\)에 대한 합\n- \\(\\mathlarger{\\mathbbm{1}}_{ij}^{\\text{ objective}}\\): \\(i\\)번째 공간 좌표가 \\(j\\)번째 클래스에 있으면 1, 그렇지 않으면 0인 지시 함수\n- \\((x_i - \\hat{x}_i)^2\\): 원래 \\(x\\) 좌표와 추정된 \\(x\\) 좌표의 차이 제곱\n- \\((y_i - \\hat{y}_i)^2\\): 원래 \\(y\\) 좌표와 추정된 \\(y\\) 좌표의 차이 제곱입니다.\n- 이 항은 이미지 좌표의 총 제곱 오차를 측정합니다.\n\n2. **두 번째 항:**\n\\[\n   + \\lambda_\\textbf{coord}\n   \\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n         \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{ objective}}\n         \\left[\n        \\left(\n            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n        \\right)^2 +\n        \\left(\n            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n        \\right)^2\n        \\right]\n   \\]\n- 이 항은 이미지 종횡비의 총 제곱 오차를 측정합니다.\n\n3. **세 번째 항:**\n\\[\n   + \\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n        \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{ objective}}\n        \\left(\n            C_i - \\hat{C}_i\n        \\right)^2\n   \\]\n- 이 항은 이미지의 색상 채널 값의 총 제곱 오차를 측정합니다.\n\n4. **네 번째 항:**\n\\[\n   + \\lambda_\\textrm{no objective}\n   \\sum_{i = 0}^{S^2}\n    \\sum_{j = 0}^{B}\n    \\mathlarger{\\mathbbm{1}}_{ij}^{\\text{ no objective}}\n        \\left(\n            C_i - \\hat{C}_i\n        \\right)^2\n   \\]\n- 이 항은 세 번째 항과 비슷하지만 가중치 인자 \\(\\lambda_\\textrm{no objective}\\)가 다릅니다.\n\n5. **다섯 번째 항:**\n\\[\n   + \\sum_{i = 0}^{S^2}\n\\mathlarger{\\mathbbm{1}}_i^{\\text{ objective}}\n    \\sum_{c \\in \\textrm{classes}}\n        \\left(\n            p_i(c) - \\hat{p}_i(c)\n        \\right)^2\n   \\]\n- 이 항은 클래스의 확률 분포에서 총 제곱 오차를 측정합니다.\n\n### 결론\n전체 손실 함수는 이러한 모든 개별 항의 합입니다. 목표는 이 손실 함수를 최소화하여 원본 이미지에 대한 최적의 추정치를 얻는 것입니다. 가중치 인자 \\(\\lambda_\\textbf{coord}\\)와 \\(\\lambda_\\textrm{no objective}\\)를 조정하여 손실 함수에서 서로 다른 항의 기여도를 균형 있게 조절할 수 있습니다.\n\n⟦수학0⟧"
    }
  ]
}