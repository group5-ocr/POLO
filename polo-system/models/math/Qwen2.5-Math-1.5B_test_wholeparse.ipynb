{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1c5a43",
   "metadata": {},
   "source": [
    "# 코드설명\n",
    "Tex를 받아와서 수식만 뽑아낸 후\n",
    "\n",
    "중학생 이상의 수준을 요구하는 수식만 해설\n",
    "\n",
    "_build 폴더 안에 .tex파일로 생긴다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6b2df",
   "metadata": {},
   "source": [
    "### 셀 1. 환경 준비 & 모델 로드 (4-bit, CUDA 자동 감지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c65b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch file: c:\\POLO\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "torch version: 2.5.1+cu121\n",
      "pip sees torch: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch, importlib.metadata as im\n",
    "print(\"torch file:\", torch.__file__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"pip sees torch:\", im.version(\"torch\"))\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd4be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9\n",
      "PyTorch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Device selected: cuda\n",
      "Model & tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# === 셀 1: 환경 준비 & 모델 로드 ===\n",
    "import os, torch, sys, platform, json, re, textwrap, subprocess, shutil\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ----- 기본 경로 설정 -----\n",
    "# INPUT_TEX_PATH = r\"C:\\POLO\\polo-system\\models\\math\\iclr2022_conference.tex\"        # <- 분석할 LaTeX 파일 경로\n",
    "INPUT_TEX_PATH = r\"C:\\POLO\\polo-system\\models\\math\\yolo.tex\"        # <- 분석할 LaTeX 파일 경로\n",
    "OUT_DIR        = \"C:/POLO/polo-system/models/math./_build\"          # 산출물 폴더 경로\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----- 모델/토크나이저 설정 -----\n",
    "MODEL_ID = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"   # 1.5B 수학 특화 instruct\n",
    "USE_4BIT = True                                 # 8GB VRAM을 고려한 4-bit 양자화\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Device selected: {DEVICE}\")\n",
    "\n",
    "# ----- 모델 로드 -----\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "bnb_config = None\n",
    "if USE_4BIT:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True \n",
    ")\n",
    "\n",
    "# 공통 generate 설정\n",
    "GEN_KW = dict(\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(\"Model & tokenizer loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcc565",
   "metadata": {},
   "source": [
    "### 셀 2. LaTeX 파서: 수식 추출(인라인/디스플레이/환경) + 라인번호 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134f4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 수식 개수: 66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'kind': 'inline($ $)',\n",
       "  'env': '',\n",
       "  'start': 1801,\n",
       "  'end': 1805,\n",
       "  'line_start': 63,\n",
       "  'line_end': 63,\n",
       "  'body': '^*'},\n",
       " {'kind': 'inline($ $)',\n",
       "  'env': '',\n",
       "  'start': 1822,\n",
       "  'end': 1833,\n",
       "  'line_start': 63,\n",
       "  'line_end': 63,\n",
       "  'body': '^{* \\\\dag}'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 셀 2: LaTeX 수식 추출 유틸 ===\n",
    "from pathlib import Path\n",
    "\n",
    "assert Path(INPUT_TEX_PATH).exists(), f\"입력 TeX 파일을 찾을 수 없습니다: {INPUT_TEX_PATH}\"\n",
    "src = Path(INPUT_TEX_PATH).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# 라인 오프셋 인덱스\n",
    "lines = src.splitlines()\n",
    "offsets = []\n",
    "pos = 0\n",
    "for ln in lines:\n",
    "    offsets.append(pos)\n",
    "    pos += len(ln) + 1\n",
    "\n",
    "def pos_to_line(p:int)->int:\n",
    "    lo, hi = 0, len(offsets)-1\n",
    "    while lo <= hi:\n",
    "        mid = (lo+hi)//2\n",
    "        if offsets[mid] <= p:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            hi = mid - 1\n",
    "    return hi + 1  # 1-based\n",
    "\n",
    "def extract_equations(tex:str)->List[Dict]:\n",
    "    matches = []\n",
    "    def add(kind, start, end, body, env=\"\"):\n",
    "        matches.append({\n",
    "            \"kind\": kind, \"env\": env, \"start\": start, \"end\": end,\n",
    "            \"line_start\": pos_to_line(start), \"line_end\": pos_to_line(end),\n",
    "            \"body\": body.strip()\n",
    "        })\n",
    "    # $$ ... $$\n",
    "    for m in re.finditer(r\"\\$\\$(.+?)\\$\\$\", tex, flags=re.DOTALL):\n",
    "        add(\"display($$ $$)\", m.start(), m.end(), m.group(1))\n",
    "    # \\[ ... \\]\n",
    "    for m in re.finditer(r\"\\\\\\[(.+?)\\\\\\]\", tex, flags=re.DOTALL):\n",
    "        add(\"display(\\\\[ \\\\])\", m.start(), m.end(), m.group(1))\n",
    "    # \\( ... \\)\n",
    "    for m in re.finditer(r\"\\\\\\((.+?)\\\\\\)\", tex, flags=re.DOTALL):\n",
    "        add(\"inline(\\\\( \\\\))\", m.start(), m.end(), m.group(1))\n",
    "    # inline $...$ (단, $$ 제외)\n",
    "    for m in re.finditer(r\"(?<!\\$)\\$(?!\\$)(.+?)(?<!\\$)\\$(?!\\$)\", tex, flags=re.DOTALL):\n",
    "        add(\"inline($ $)\", m.start(), m.end(), m.group(1))\n",
    "    # environments\n",
    "    envs = [\"equation\",\"equation*\",\"align\",\"align*\",\"multline\",\"multline*\",\"gather\",\"gather*\",\"flalign\",\"flalign*\",\"eqnarray\",\"eqnarray*\",\"split\"]\n",
    "    for env in envs:\n",
    "        pattern = rf\"\\\\begin{{{re.escape(env)}}}(.+?)\\\\end{{{re.escape(env)}}}\"\n",
    "        for m in re.finditer(pattern, tex, flags=re.DOTALL):\n",
    "            add(f\"env\", m.start(), m.end(), m.group(1), env=env)\n",
    "    # 중복(동일 범위) 제거 및 정렬\n",
    "    uniq = {}\n",
    "    for it in matches:\n",
    "        key = (it[\"start\"], it[\"end\"])\n",
    "        if key not in uniq:\n",
    "            uniq[key] = it\n",
    "    out = list(uniq.values())\n",
    "    out.sort(key=lambda x: x[\"start\"])\n",
    "    return out\n",
    "\n",
    "equations_all = extract_equations(src)\n",
    "print(f\"총 수식 개수: {len(equations_all)}\")\n",
    "equations_all[:2]  # 미리보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb8992e",
   "metadata": {},
   "source": [
    "### 셀 3. “중학생 수준 이상” 판별 휴리스틱\n",
    "\n",
    "> 기본적으로 ∑, ∂, argmax, 분수·제곱근의 중첩, 좌표/박스 지시자 등 조금 복합적인 표기가 있으면 상위 난이도로 분류합니다. 프로젝트에 맞게 규칙을 쉽게 커스터마이즈할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312366e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중학생 수준 이상으로 분류된 수식: 19 / 66\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LaTeX 수식 해설 API (FastAPI)\n",
    "- uvicorn --reload app:app 로 실행\n",
    "- GET  /health                         : 상태 체크\n",
    "- GET  /count/{file_path:path}         : 수식 개수만 세기(간단 확인용)\n",
    "- POST /count                          : JSON {\"path\": \"C:\\\\...\\\\yolo.tex\"}\n",
    "- GET  /math/{file_path:path}          : 파일 경로를 URL path로 넘겨 실행\n",
    "- POST /math                           : JSON {\"path\": \"C:\\\\...\\\\yolo.tex\"}\n",
    "\n",
    "참고 사항\n",
    "- 콘솔 출력이 바로 보이도록 stdout 라인 버퍼링 + flush=True 적용\n",
    "- pad==eos 경고 방지를 위해 pad 토큰 추가 + attention_mask 명시\n",
    "\"\"\"\n",
    "\n",
    "# === 셀 1: 환경 준비 & 모델 로드 ===\n",
    "import os, torch, sys, json, re, textwrap, datetime\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# stdout 라인 버퍼링 (print 즉시 표시)\n",
    "try:\n",
    "    sys.stdout.reconfigure(line_buffering=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "VERSION = \"POLO-Math-API v3 (flush+mask+pad)\"; print(VERSION, flush=True)\n",
    "\n",
    "# ----- 기본 경로 설정 -----\n",
    "INPUT_TEX_PATH = r\"C:\\\\POLO\\\\polo-system\\\\models\\\\math\\\\yolo.tex\"  # 예시 경로\n",
    "OUT_DIR        = \"C:/POLO/polo-system/models/math/_build\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----- 모델/토크나이저 설정 -----\n",
    "MODEL_ID = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n",
    "USE_4BIT = False\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\", flush=True)\n",
    "print(f\"PyTorch: {torch.__version__}\", flush=True)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\", flush=True)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\", flush=True)\n",
    "print(f\"Device selected: {DEVICE}\", flush=True)\n",
    "\n",
    "# ----- 모델 로드 -----\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "    # pad_token 경고 완화: pad 없거나 eos와 같으면 [PAD] 추가\n",
    "    PAD_ADDED = False\n",
    "    if tokenizer.pad_token_id is None or tokenizer.pad_token_id == tokenizer.eos_token_id:\n",
    "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        PAD_ADDED = True\n",
    "\n",
    "    bnb_config = None\n",
    "    if USE_4BIT:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "        quantization_config=bnb_config,\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    if PAD_ADDED:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # 공통 generate 설정\n",
    "    GEN_KW = dict(\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    print(\"Model & tokenizer loaded.\", flush=True)\n",
    "except Exception as e:\n",
    "    tokenizer = None\n",
    "    model = None\n",
    "    GEN_KW = {}\n",
    "    print(\"[Model Load Error]\", e, flush=True)\n",
    "\n",
    "\n",
    "# === 공용 유틸: 라인 위치 계산 ===\n",
    "def make_line_offsets(text: str) -> List[int]:\n",
    "    lines = text.splitlines()\n",
    "    offsets, pos = [], 0\n",
    "    for ln in lines:\n",
    "        offsets.append(pos)\n",
    "        pos += len(ln) + 1  # '\\n'\n",
    "    return offsets\n",
    "\n",
    "def build_pos_to_line(offsets: List[int]):\n",
    "    def pos_to_line(p: int) -> int:\n",
    "        lo, hi = 0, len(offsets)-1\n",
    "        while lo <= hi:\n",
    "            mid = (lo+hi)//2\n",
    "            if offsets[mid] <= p:\n",
    "                lo = mid + 1\n",
    "            else:\n",
    "                hi = mid - 1\n",
    "        return hi + 1  # 1-based\n",
    "    return pos_to_line\n",
    "\n",
    "\n",
    "# === 셀 2: LaTeX 수식 추출 유틸 ===\n",
    "def extract_equations(tex: str, pos_to_line) -> List[Dict]:\n",
    "    matches: List[Dict] = []\n",
    "\n",
    "    def add(kind, start, end, body, env=\"\"):\n",
    "        matches.append({\n",
    "            \"kind\": kind, \"env\": env, \"start\": start, \"end\": end,\n",
    "            \"line_start\": pos_to_line(start), \"line_end\": pos_to_line(end),\n",
    "            \"body\": body.strip()\n",
    "        })\n",
    "\n",
    "    # $$ ... $$\n",
    "    for m in re.finditer(r\"\\$\\$(.+?)\\$\\$\", tex, flags=re.DOTALL):\n",
    "        add(\"display($$ $$)\", m.start(), m.end(), m.group(1))\n",
    "    # \\[ ... \\]\n",
    "    for m in re.finditer(r\"\\\\\\[(.+?)\\\\\\]\", tex, flags=re.DOTALL):\n",
    "        add(\"display(\\\\[ \\\\])\", m.start(), m.end(), m.group(1))\n",
    "    # \\( ... \\)\n",
    "    for m in re.finditer(r\"\\\\\\((.+?)\\\\\\)\", tex, flags=re.DOTALL):\n",
    "        add(\"inline(\\\\( \\\\))\", m.start(), m.end(), m.group(1))\n",
    "    # inline $...$ (단, $$ 제외)\n",
    "    for m in re.finditer(r\"(?<!\\$)\\$(?!\\$)(.+?)(?<!\\$)\\$(?!\\$)\", tex, flags=re.DOTALL):\n",
    "        add(\"inline($ $)\", m.start(), m.end(), m.group(1))\n",
    "    # environments\n",
    "    envs = [\"equation\",\"equation*\",\"align\",\"align*\",\"multline\",\"multline*\",\n",
    "            \"gather\",\"gather*\",\"flalign\",\"flalign*\",\"eqnarray\",\"eqnarray*\",\"split\"]\n",
    "    for env in envs:\n",
    "        pattern = rf\"\\\\begin{{{re.escape(env)}}}(.+?)\\\\end{{{re.escape(env)}}}\"\n",
    "        for m in re.finditer(pattern, tex, flags=re.DOTALL):\n",
    "            add(\"env\", m.start(), m.end(), m.group(1), env=env)\n",
    "\n",
    "    # 중복(동일 범위) 제거 및 정렬\n",
    "    uniq = {}\n",
    "    for it in matches:\n",
    "        key = (it[\"start\"], it[\"end\"])\n",
    "        if key not in uniq:\n",
    "            uniq[key] = it\n",
    "    out = list(uniq.values())\n",
    "    out.sort(key=lambda x: x[\"start\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "# === 셀 3: 난이도 휴리스틱 정의 (요청하신 버전 반영) ===\n",
    "ADV_TOKENS = [\n",
    "    r\"\\\\sum\", r\"\\\\prod\", r\"\\\\int\", r\"\\\\lim\", r\"\\\\nabla\", r\"\\\\partial\",\n",
    "    r\"\\\\mathbb\", r\"\\\\mathcal\", r\"\\\\mathbf\", r\"\\\\boldsymbol\",\n",
    "    r\"\\\\argmax\", r\"\\\\argmin\", r\"\\\\operatorname\", r\"\\\\mathrm\\{KL\\}\",\n",
    "    r\"\\\\mathbb\\{E\\}\", r\"\\\\Pr\", r\"\\\\sigma\", r\"\\\\mu\", r\"\\\\Sigma\", r\"\\\\theta\",\n",
    "    r\"\\\\frac\\{[^{}]*\\{[^{}]*\\}[^{}]*\\}\",  # 중첩 분수\n",
    "    r\"\\\\hat\\{\", r\"\\\\tilde\\{\", r\"\\\\bar\\{\", r\"\\\\widehat\\{\", r\"\\\\widetilde\\{\",\n",
    "    r\"\\\\sqrt\\{[^{}]*\\{\",                   # 중첩 sqrt\n",
    "    r\"\\\\left\", r\"\\\\right\",\n",
    "    r\"\\\\in\", r\"\\\\subset\", r\"\\\\forall\", r\"\\\\exists\",\n",
    "    r\"\\\\cdot\", r\"\\\\times\", r\"\\\\otimes\",\n",
    "    r\"IoU\", r\"\\\\log\", r\"\\\\exp\",\n",
    "    r\"\\\\mathbb\\{R\\}\", r\"\\\\mathbb\\{N\\}\", r\"\\\\mathbb\\{Z\\}\",\n",
    "    r\"\\\\Delta\", r\"\\\\delta\", r\"\\\\epsilon\", r\"\\\\varepsilon\",\n",
    "]\n",
    "ADV_RE = re.compile(\"|\".join(ADV_TOKENS))\n",
    "\n",
    "def count_subscripts(expr: str) -> int:\n",
    "    return len(re.findall(r\"_[a-zA-Z0-9{\\\\]\", expr))\n",
    "\n",
    "def is_advanced(eq: str) -> bool:\n",
    "    if ADV_RE.search(eq):\n",
    "        return True\n",
    "    if len(eq) > 40 and count_subscripts(eq) >= 2:\n",
    "        return True\n",
    "    if \"\\n\" in eq and len(eq) > 30:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# === 셀 4: 문서 전체 개요 생성 (모델 요약) ===\n",
    "def take_slices(text: str, head_chars=4000, mid_chars=2000, tail_chars=4000):\n",
    "    n = len(text)\n",
    "    head = text[:min(head_chars, n)]\n",
    "    mid_start = max((n // 2) - (mid_chars // 2), 0)\n",
    "    mid = text[mid_start: mid_start + min(mid_chars, n)]\n",
    "    tail = text[max(0, n - tail_chars):]\n",
    "    return head, mid, tail\n",
    "\n",
    "def _generate_with_mask_from_messages(messages: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    attention_mask를 명시해 경고 방지 및 일관 동작 보장.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True, return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "    # pad_token_id가 정의되어 있으므로 mask를 정확히 생성\n",
    "    attention_mask = (inputs != tokenizer.pad_token_id).long()\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            input_ids=inputs.to(model.device),\n",
    "            attention_mask=attention_mask.to(model.device),\n",
    "            **GEN_KW\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "def chat(prompt: str) -> str:\n",
    "    if tokenizer is None or model is None:\n",
    "        raise RuntimeError(\"Model is not loaded.\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 AI 논문/수식을 한국어로 쉽게 설명하는 선생님입니다. 항상 존댓말로 답변합니다.\"},\n",
    "        {\"role\": \"user\",   \"content\": prompt}\n",
    "    ]\n",
    "    text = _generate_with_mask_from_messages(messages)\n",
    "    return text.split(messages[-1][\"content\"])[-1].strip()\n",
    "\n",
    "\n",
    "# === 셀 5: 수식 해설 생성 ===\n",
    "EXPLAIN_SYSTEM = \"You are a teacher who explains math/AI research equations in clear, simple English. Always answer politely and understandably.\"\n",
    "EXPLAIN_TEMPLATE = (\n",
    "    \"\"\"Please explain the following equation so that it can be understood by someone at least at a middle school level.\n",
    "Follow this exact order in your output: Example → Explanation → Conclusion\n",
    "\n",
    "- Example: Show the equation exactly as LaTeX in a single block (do not modify or add anything).\n",
    "- Explanation: Provide bullet points explaining the meaning of symbols (∑, 𝟙, ^, _, √, \\\\, etc.) and the role of each term, in a clear and concise way.\n",
    "- Conclusion: Summarize in one sentence the core purpose of this equation in the context of the paper (e.g., loss composition, normalization, coordinate error, probability/log-likelihood, etc.).\n",
    "- (Important) Do not change the symbols or the order of the equation, and do not invent new symbols.\n",
    "- (Important) Write only in English.\n",
    "\n",
    "[Equation]\n",
    "{EQUATION}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def explain_equation_with_llm(eq_latex: str) -> str:\n",
    "    if tokenizer is None or model is None:\n",
    "        raise RuntimeError(\"Model is not loaded.\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": EXPLAIN_SYSTEM},\n",
    "        {\"role\": \"user\",   \"content\": EXPLAIN_TEMPLATE.format(EQUATION=eq_latex)}\n",
    "    ]\n",
    "    text = _generate_with_mask_from_messages(messages)\n",
    "    return text.split(messages[-1][\"content\"])[:-1][-1].strip() if messages[-1][\"content\"] in text else text\n",
    "\n",
    "\n",
    "# === 셀 6: LaTeX 리포트(.tex) 만들기 ===\n",
    "def latex_escape_verbatim(s: str) -> str:\n",
    "    s = s.replace(\"\\\\\", r\"\\\\\")\n",
    "    s = s.replace(\"#\", r\"\\#\").replace(\"$\", r\"\\$\")\n",
    "    s = s.replace(\"%\", r\"\\%\").replace(\"&\", r\"\\&\")\n",
    "    s = s.replace(\"_\", r\"\\_\").replace(\"{\", r\"\\{\").replace(\"}\", r\"\\}\")\n",
    "    s = s.replace(\"^\", r\"\\^{}\").replace(\"~\", r\"\\~{}\")\n",
    "    return s\n",
    "\n",
    "def build_report(overview: str, items: List[Dict]) -> str:\n",
    "    header = (r\"\"\"\\\\documentclass[11pt]{article}\n",
    "\\\\usepackage[margin=1in]{geometry}\n",
    "\\\\usepackage{amsmath, amssymb, amsfonts}\n",
    "\\\\usepackage{hyperref}\n",
    "\\\\usepackage{kotex} % Windows MiKTeX에 설치되어 있어야 함 (없으면 xelatex/xeCJK로 컴파일)\n",
    "\\\\setlength{\\\\parskip}{6pt}\n",
    "\\\\setlength{\\\\parindent}{0pt}\n",
    "\\\\title{LaTeX 문서 수식 해설 리포트 (중학생 수준 이상)}\n",
    "\\\\author{자동 생성 파이프라인}\n",
    "\\\\date{\"\"\" + datetime.date.today().isoformat() + r\"\"\"}\n",
    "\\\\begin{document}\n",
    "\\\\maketitle\n",
    "\\\\tableofcontents\n",
    "\\\\newpage\n",
    "\"\"\")\n",
    "    parts = [header]\n",
    "    parts.append(r\"\\\\section*{문서 개요}\")\n",
    "    parts.append(latex_escape_verbatim(overview))\n",
    "    parts.append(\"\\n\\\\newpage\\n\")\n",
    "\n",
    "    for it in items:\n",
    "        title = f\"라인 {it['line_start']}–{it['line_end']} / {it['kind']} {('['+it['env']+']') if it['env'] else ''}\"\n",
    "        parts.append(f\"\\\\section*{{{latex_escape_verbatim(title)}}}\")\n",
    "        parts.append(it[\"explanation\"])  # LLM 출력 그대로 삽입\n",
    "        parts.append(\"\\n\")\n",
    "\n",
    "    parts.append(\"\\\\end{document}\\n\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "# === 새로 추가: 수식 개수만 세기 ===\n",
    "def count_equations_only(input_tex_path: str) -> Dict[str, int]:\n",
    "    p = Path(input_tex_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"입력 TeX 파일을 찾을 수 없습니다: {input_tex_path}\")\n",
    "\n",
    "    src = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    offsets = make_line_offsets(src)\n",
    "    pos_to_line = build_pos_to_line(offsets)\n",
    "\n",
    "    equations_all = extract_equations(src, pos_to_line)\n",
    "    equations_advanced = [e for e in equations_all if is_advanced(e[\"body\"])]\n",
    "\n",
    "    # 콘솔 출력 (즉시 표시)\n",
    "    print(f\"총 수식 개수: {len(equations_all)}\", flush=True)\n",
    "    print(f\"중학생 수준 이상으로 분류된 수식: {len(equations_advanced)} / {len(equations_all)}\", flush=True)\n",
    "\n",
    "    return {\n",
    "        \"equations_total\": len(equations_all),\n",
    "        \"equations_advanced\": len(equations_advanced)\n",
    "    }\n",
    "\n",
    "\n",
    "# === 파이프라인 실행 함수 ===\n",
    "def run_pipeline(input_tex_path: str) -> Dict:\n",
    "    p = Path(input_tex_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"입력 TeX 파일을 찾을 수 없습니다: {input_tex_path}\")\n",
    "\n",
    "    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    src = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    offsets = make_line_offsets(src)\n",
    "    pos_to_line = build_pos_to_line(offsets)\n",
    "\n",
    "    # 1) 수식 추출 & 고난도 분류\n",
    "    equations_all = extract_equations(src, pos_to_line)\n",
    "    equations_advanced = [e for e in equations_all if is_advanced(e[\"body\"])]\n",
    "\n",
    "    # 콘솔 요약 출력 (즉시 표시)\n",
    "    print(f\"총 수식 개수: {len(equations_all)}\", flush=True)\n",
    "    print(f\"중학생 수준 이상으로 분류된 수식: {len(equations_advanced)} / {len(equations_all)}\", flush=True)\n",
    "\n",
    "    # 2) 문서 개요 요약\n",
    "    head, mid, tail = take_slices(src)\n",
    "    overview_prompt = textwrap.dedent(f\"\"\"\n",
    "    다음 LaTeX 문서의 앞/중/뒤 일부를 보여드립니다.\n",
    "    - 핵심 주제/목표를 한 문단으로 요약하시고,\n",
    "    - 주요 섹션(있다면)을 불릿으로 정리해 주세요.\n",
    "    - 수학 표기/기호 해석에 초점을 맞춰, 전체 흐름을 설명해 주세요.\n",
    "    - 항상 한국어 존댓말로, 너무 길지 않게.\n",
    "\n",
    "    [앞부분]\n",
    "    {head}\n",
    "\n",
    "    [중간]\n",
    "    {mid}\n",
    "\n",
    "    [뒷부분]\n",
    "    {tail}\n",
    "    \"\"\").strip()\n",
    "    doc_overview = chat(overview_prompt)\n",
    "\n",
    "    # 3) 수식별 해설 생성\n",
    "    explanations: List[Dict] = []\n",
    "    for idx, item in enumerate(equations_advanced, start=1):\n",
    "        print(f\"[{idx}/{len(equations_advanced)}] 라인 {item['line_start']}–{item['line_end']}\", flush=True)\n",
    "        exp = explain_equation_with_llm(item[\"body\"])\n",
    "        explanations.append({\n",
    "            \"index\": idx,\n",
    "            \"line_start\": item[\"line_start\"],\n",
    "            \"line_end\": item[\"line_end\"],\n",
    "            \"kind\": item[\"kind\"],\n",
    "            \"env\": item[\"env\"],\n",
    "            \"equation\": item[\"body\"],\n",
    "            \"explanation\": exp\n",
    "        })\n",
    "\n",
    "    # 4) JSON 저장\n",
    "    json_path = os.path.join(OUT_DIR, \"equations_explained.json\")\n",
    "    Path(json_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"overview\": doc_overview, \"items\": explanations}, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"저장 완료(JSON): {json_path}\", flush=True)\n",
    "\n",
    "    # 5) LaTeX 리포트(.tex) 생성\n",
    "    report_tex_path = os.path.join(OUT_DIR, \"yolo_math_report.tex\")\n",
    "    report_tex = build_report(doc_overview, explanations)\n",
    "    Path(report_tex_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(report_tex_path).write_text(report_tex, encoding=\"utf-8\")\n",
    "    print(f\"저장 완료(TeX): {report_tex_path}\", flush=True)\n",
    "\n",
    "    return {\n",
    "        \"input\": str(p),\n",
    "        \"counts\": {\n",
    "            \"equations_total\": len(equations_all),\n",
    "            \"equations_advanced\": len(equations_advanced)\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"json\": json_path,\n",
    "            \"report_tex\": report_tex_path,\n",
    "            \"out_dir\": OUT_DIR\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# === FastAPI 앱 정의 ===\n",
    "app = FastAPI(title=\"POLO Math Explainer API\", version=\"1.0.0\")\n",
    "\n",
    "class MathRequest(BaseModel):\n",
    "    path: str\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"torch\": torch.__version__,\n",
    "        \"cuda\": torch.cuda.is_available(),\n",
    "        \"device\": DEVICE,\n",
    "        \"model_loaded\": (tokenizer is not None and model is not None)\n",
    "    }\n",
    "\n",
    "# 수식 개수만 세는 엔드포인트 (GET/POST)\n",
    "@app.get(\"/count/{file_path:path}\")\n",
    "async def count_get(file_path: str):\n",
    "    try:\n",
    "        return count_equations_only(file_path)\n",
    "    except FileNotFoundError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"처리 중 오류: {e}\")\n",
    "\n",
    "@app.post(\"/count\")\n",
    "async def count_post(req: MathRequest):\n",
    "    try:\n",
    "        return count_equations_only(req.path)\n",
    "    except FileNotFoundError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"처리 중 오류: {e}\")\n",
    "\n",
    "@app.post(\"/math\")\n",
    "async def math_post(req: MathRequest):\n",
    "    try:\n",
    "        return run_pipeline(req.path)\n",
    "    except FileNotFoundError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"처리 중 오류: {e}\")\n",
    "\n",
    "@app.get(\"/math/{file_path:path}\")\n",
    "async def math_get(file_path: str):\n",
    "    try:\n",
    "        return run_pipeline(file_path)\n",
    "    except FileNotFoundError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"처리 중 오류: {e}\")\n",
    "\n",
    "# 로컬에서 python app.py 로 실행할 때 편의를 위한 엔트리포인트\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\"app:app\", host=\"127.0.0.1\", port=8000, reload=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70d70b",
   "metadata": {},
   "source": [
    "### 셀 4. “문서 전체 이해” 요약(개요/섹션 요지) 생성\n",
    "\n",
    "> .tex 전체를 그대로 넣기엔 길 수 있으므로 토막 요약 방식(앞/중/뒤 샘플링)으로 개요를 뽑습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ebd4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "\\end{document}\n"
     ]
    }
   ],
   "source": [
    "# === 셀 4: 문서 전체 개요 생성 (모델 요약) ===\n",
    "def take_slices(text:str, head_chars=4000, mid_chars=2000, tail_chars=4000):\n",
    "    n = len(text)\n",
    "    head = text[:min(head_chars, n)]\n",
    "    mid_start = max((n//2) - (mid_chars//2), 0)\n",
    "    mid = text[mid_start: mid_start + min(mid_chars, n)]\n",
    "    tail = text[max(0, n - tail_chars):]\n",
    "    return head, mid, tail\n",
    "\n",
    "head, mid, tail = take_slices(src)\n",
    "\n",
    "def chat(prompt:str)->str:\n",
    "    # Qwen2.5 Instruct 포맷 간단 사용\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"당신은 AI 논문/수식을 한국어로 쉽게 설명하는 선생님입니다. 항상 존댓말로 답변합니다.\"},\n",
    "        {\"role\":\"user\", \"content\": prompt}\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(input_ids=input_ids, **GEN_KW)\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    # chat 템플릿 접두부 제거\n",
    "    return text.split(messages[-1][\"content\"])[-1].strip()\n",
    "\n",
    "overview_prompt = textwrap.dedent(f\"\"\"\n",
    "다음 LaTeX 문서의 앞/중/뒤 일부를 보여드립니다.\n",
    "- 핵심 주제/목표를 한 문단으로 요약하시고,\n",
    "- 주요 섹션(있다면)을 불릿으로 정리해 주세요.\n",
    "- 수학 표기/기호 해석에 초점을 맞춰, 전체 흐름을 설명해 주세요.\n",
    "- 항상 한국어 존댓말로, 너무 길지 않게.\n",
    "\n",
    "[앞부분]\n",
    "{head}\n",
    "\n",
    "[중간]\n",
    "{mid}\n",
    "\n",
    "[뒷부분]\n",
    "{tail}\n",
    "\"\"\").strip()\n",
    "\n",
    "doc_overview = chat(overview_prompt)\n",
    "print(doc_overview[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2a3a4",
   "metadata": {},
   "source": [
    "### 셀 5. 수식 해설(예시 → 설명 → 결론) 생성 함수 + 배치 실행\n",
    "\n",
    "> 각 수식은 원문을 그대로 제시하고, 상징/기호의 의미와 YOLO 맥락(좌표, 지시자 𝟙, √w_i 등)을 반영해 한국어/존댓말/미괄식으로 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f923056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/19] 라인 91–91\n",
      "[2/19] 라인 118–118\n",
      "[3/19] 라인 120–120\n",
      "[4/19] 라인 124–124\n",
      "[5/19] 라인 127–130\n",
      "[6/19] 라인 138–138\n",
      "[7/19] 라인 138–138\n",
      "[8/19] 라인 142–142\n",
      "[9/19] 라인 150–150\n",
      "[10/19] 라인 150–150\n",
      "[11/19] 라인 156–156\n",
      "[12/19] 라인 156–156\n",
      "[13/19] 라인 160–160\n",
      "[14/19] 라인 173–173\n",
      "[15/19] 라인 173–173\n",
      "[16/19] 라인 179–185\n",
      "[17/19] 라인 198–246\n",
      "[18/19] 라인 248–248\n",
      "[19/19] 라인 248–248\n",
      "저장 완료: C:/POLO/polo-system/models/math./_build\\equations_explained.json\n"
     ]
    }
   ],
   "source": [
    "# === 셀 5: 수식 해설 생성 ===\n",
    "EXPLAIN_SYSTEM = \"You are a teacher who explains math/AI research equations in clear, simple English. Always answer politely and understandably.\"\n",
    "\n",
    "EXPLAIN_TEMPLATE = \"\"\"Please explain the following equation so that it can be understood by someone at least at a middle school level.\n",
    "Follow this exact order in your output: Example → Explanation → Conclusion\n",
    "\n",
    "- Example: Show the equation exactly as LaTeX in a single block (do not modify or add anything).\n",
    "- Explanation: Provide bullet points explaining the meaning of symbols (∑, 𝟙, ^, _, √, \\\\, etc.) and the role of each term, in a clear and concise way.\n",
    "- Conclusion: Summarize in one sentence the core purpose of this equation in the context of the paper (e.g., loss composition, normalization, coordinate error, probability/log-likelihood, etc.).\n",
    "- (Important) Do not change the symbols or the order of the equation, and do not invent new symbols.\n",
    "- (Important) Write only in English.\n",
    "\n",
    "[Equation]\n",
    "{EQUATION}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def explain_equation_with_llm(eq_latex:str)->str:\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": EXPLAIN_SYSTEM},\n",
    "        {\"role\":\"user\", \"content\": EXPLAIN_TEMPLATE.format(EQUATION=eq_latex)}\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(input_ids=input_ids, **GEN_KW)\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    return text.split(messages[-1][\"content\"])[-1].strip()\n",
    "\n",
    "# 배치 실행 (너무 많으면 여러 번에 나누세요)\n",
    "explanations = []\n",
    "for idx, item in enumerate(equations_advanced, start=1):\n",
    "    print(f\"[{idx}/{len(equations_advanced)}] 라인 {item['line_start']}–{item['line_end']}\")\n",
    "    exp = explain_equation_with_llm(item[\"body\"])\n",
    "    explanations.append({\n",
    "        \"index\": idx,\n",
    "        \"line_start\": item[\"line_start\"],\n",
    "        \"line_end\": item[\"line_end\"],\n",
    "        \"kind\": item[\"kind\"],\n",
    "        \"env\": item[\"env\"],\n",
    "        \"equation\": item[\"body\"],\n",
    "        \"explanation\": exp\n",
    "    })\n",
    "\n",
    "# 중간 저장\n",
    "json_path = os.path.join(OUT_DIR, \"equations_explained.json\")\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"overview\": doc_overview,\n",
    "        \"items\": explanations\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "print(f\"저장 완료: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d30a1c",
   "metadata": {},
   "source": [
    "### 셀 6. LaTeX 리포트 생성(.tex) — 개요 + 수식별 해설\n",
    "\n",
    "> MiKTeX(Windows) 또는 TeX Live가 있어야 PDF 컴파일 가능합니다. 없으면 다음 셀에서 설치 안내/에러 메시지를 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7a9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX 리포트 생성: C:/POLO/polo-system/models/math./_build\\yolo_math_report.tex\n"
     ]
    }
   ],
   "source": [
    "# === 셀 6: LaTeX 리포트(.tex) 만들기 ===\n",
    "import datetime\n",
    "\n",
    "report_tex_path = os.path.join(OUT_DIR, \"yolo_math_report.tex\")\n",
    "\n",
    "def latex_escape_verbatim(s:str)->str:\n",
    "    # 설명 텍스트 내 LaTeX 특수문자 간단 이스케이프\n",
    "    s = s.replace(\"\\\\\", r\"\\\\\")\n",
    "    s = s.replace(\"#\", r\"\\#\").replace(\"$\", r\"\\$\")\n",
    "    s = s.replace(\"%\", r\"\\%\").replace(\"&\", r\"\\&\")\n",
    "    s = s.replace(\"_\", r\"\\_\").replace(\"{\", r\"\\{\").replace(\"}\", r\"\\}\")\n",
    "    s = s.replace(\"^\", r\"\\^{}\").replace(\"~\", r\"\\~{}\")\n",
    "    return s\n",
    "\n",
    "def build_report(overview:str, items:List[Dict])->str:\n",
    "    header = r\"\"\"\\documentclass[11pt]{article}\n",
    "\\usepackage[margin=1in]{geometry}\n",
    "\\usepackage{amsmath, amssymb, amsfonts}\n",
    "\\usepackage{hyperref}\n",
    "\\usepackage{kotex} % Windows MiKTeX에 설치되어 있어야 함 (없으면 xelatex/xeCJK로 컴파일)\n",
    "\\setlength{\\parskip}{6pt}\n",
    "\\setlength{\\parindent}{0pt}\n",
    "\\title{LaTeX 문서 수식 해설 리포트 (중학생 수준 이상)}\n",
    "\\author{자동 생성 파이프라인}\n",
    "\\date{\"\"\" + datetime.date.today().isoformat() + r\"\"\"}\n",
    "\\begin{document}\n",
    "\\maketitle\n",
    "\\tableofcontents\n",
    "\\newpage\n",
    "\"\"\"\n",
    "    parts = [header]\n",
    "    # 개요\n",
    "    parts.append(r\"\\section*{문서 개요}\")\n",
    "    parts.append(latex_escape_verbatim(overview))\n",
    "    parts.append(\"\\n\\\\newpage\\n\")\n",
    "\n",
    "    # 각 수식\n",
    "    for it in items:\n",
    "        title = f\"라인 {it['line_start']}–{it['line_end']} / {it['kind']} {('['+it['env']+']') if it['env'] else ''}\"\n",
    "        parts.append(f\"\\\\section*{{{latex_escape_verbatim(title)}}}\")\n",
    "        # 예시 → 설명 → 결론 (LLM 출력 그대로 삽입, 단 수식 블록은 유지)\n",
    "        # 모델 출력 중 코드블록이 있다면 제거하고 LaTeX 수식만 남기는 게 안전\n",
    "        exp_txt = it[\"explanation\"]\n",
    "        parts.append(exp_txt)\n",
    "        parts.append(\"\\n\")\n",
    "\n",
    "    parts.append(\"\\\\end{document}\\n\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "report_tex = build_report(doc_overview, explanations)\n",
    "Path(report_tex_path).write_text(report_tex, encoding=\"utf-8\")\n",
    "print(f\"LaTeX 리포트 생성: {report_tex_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc0d23",
   "metadata": {},
   "source": [
    "딱 여기 셀6까지만 실행하고 파일 확인하시면 됩니다! 7번부터는 이런저런거 깔아야하고 방향성을 다시 잡는 중이라..\n",
    "\n",
    "section별로 나뉘어 있습니다! 드래그해서 지피티한테 한글로 번역. 틀려도 그대로 이렇게 주문하시면 됩니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc0e2b",
   "metadata": {},
   "source": [
    "### 셀 7. PDF 컴파일 시도 (pdflatex → xelatex 순서)\n",
    "\n",
    "> 미설치 시 MiKTeX 설치 후 PATH 반영이 필요합니다. 실패해도 .tex는 생성되어 있으니, 로컬에서 GUI(MiKTeX Console)로 컴파일하셔도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e220663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Trying: pdflatex -interaction=nonstopmode -halt-on-error yolo_math_report.tex\n",
      "실패 코드: 127\n",
      "\n",
      "Command not found: pdflatex\n",
      ">> Trying: xelatex -interaction=nonstopmode -halt-on-error yolo_math_report.tex\n",
      "실패 코드: 127\n",
      "\n",
      "Command not found: xelatex\n",
      "PDF 컴파일에 실패했습니다. MiKTeX 또는 TeX Live 설치/패키지(kotex) 확인 후 다시 시도해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# === 셀 7: PDF 컴파일 ===\n",
    "def run_cmd(cmd:List[str])->Tuple[int,str,str]:\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=OUT_DIR, shell=False)\n",
    "        return proc.returncode, proc.stdout, proc.stderr\n",
    "    except FileNotFoundError:\n",
    "        return 127, \"\", f\"Command not found: {cmd[0]}\"\n",
    "\n",
    "def try_compile(tex_filename:str)->Optional[str]:\n",
    "    base = os.path.splitext(tex_filename)[0]\n",
    "    pdf_path = os.path.join(OUT_DIR, base + \".pdf\")\n",
    "    for engine in [[\"pdflatex\",\"-interaction=nonstopmode\",\"-halt-on-error\",tex_filename],\n",
    "                   [\"xelatex\",\"-interaction=nonstopmode\",\"-halt-on-error\",tex_filename]]:\n",
    "        print(\">> Trying:\", \" \".join(engine))\n",
    "        code,out,err = run_cmd(engine)\n",
    "        if code == 0 and Path(pdf_path).exists():\n",
    "            print(\"PDF 생성 성공:\", pdf_path)\n",
    "            return pdf_path\n",
    "        else:\n",
    "            print(\"실패 코드:\", code)\n",
    "            print(out[:800])\n",
    "            print(err[:800])\n",
    "    return None\n",
    "\n",
    "pdf_path = try_compile(\"yolo_math_report.tex\")\n",
    "if pdf_path:\n",
    "    print(\"완료:\", pdf_path)\n",
    "else:\n",
    "    print(\"PDF 컴파일에 실패했습니다. MiKTeX 또는 TeX Live 설치/패키지(kotex) 확인 후 다시 시도해 주세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f628b",
   "metadata": {},
   "source": [
    "### 셀 8. 인덱스/로그 저장 (CSV/JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 셀 8: 인덱스/로그 저장 ===\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(equations_all)\n",
    "df_adv = pd.DataFrame(equations_advanced)\n",
    "\n",
    "df_path = os.path.join(OUT_DIR, \"equations_all.csv\")\n",
    "df_adv_path = os.path.join(OUT_DIR, \"equations_advanced.csv\")\n",
    "df.to_csv(df_path, index=False, encoding=\"utf-8-sig\")\n",
    "df_adv.to_csv(df_adv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"저장 완료:\")\n",
    "print(\" - 전체 수식 CSV :\", df_path)\n",
    "print(\" - 고난도 수식 CSV:\", df_adv_path)\n",
    "\n",
    "# 개요/설명 요약본\n",
    "summary_md = os.path.join(OUT_DIR, \"README_report_summary.md\")\n",
    "with open(summary_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# 문서 개요\\n\\n\")\n",
    "    f.write(doc_overview + \"\\n\\n\")\n",
    "    f.write(\"## 수식 통계\\n\")\n",
    "    f.write(f\"- 전체 수식: {len(equations_all)}개\\n\")\n",
    "    f.write(f\"- 고난도 수식: {len(equations_advanced)}개\\n\")\n",
    "print(\" - 요약 MD       :\", summary_md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
