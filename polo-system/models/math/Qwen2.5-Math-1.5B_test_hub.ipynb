{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ba00c4",
   "metadata": {},
   "source": [
    "### 1. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11376ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\requirement\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ✅ (필수) 기본 라이브러리 임포트\n",
    "import torch  # CUDA/장치 정보 확인 및 dtype 설정을 위해 사용\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e60c2",
   "metadata": {},
   "source": [
    "### 2. CUDA 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8055bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: True\n",
      "GPU 이름: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# ✅ CUDA 사용 가능 여부와 장치 이름 출력(디버깅용)\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())  # True면 GPU 사용 가능\n",
    "if torch.cuda.is_available():  # GPU가 있을 때만 장치명 출력\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))  # 첫 번째 GPU 이름\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc57c71",
   "metadata": {},
   "source": [
    "### 3. 수식 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a7cdd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 로컬 모델/토크나이저 로드 -------------------------------------------------\n",
    "MODEL_ID = \"Qwen/Qwen2.5-Math-1.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ac7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_map 제거, dtype로 FP16 지정\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,   # dtype → torch_dtype 로 권장\n",
    "    device_map=\"auto\",           # GPU 자동 매핑\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74365aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU로 직접 이동 (accelerate 불필요)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81ae92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad/eos 정합성\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a21aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 2) 파이프라인 구성 (model이 이미 cuda에 올라가 있으므로 device 지정 불필요) ---\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9e7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 수식(LaTeX) ----------------------------------------------------------------\n",
    "EQN = r\"\"\"\n",
    "\\begin{align}\n",
    "    \\max_{\\Theta} \\sum_{(x,y)\\in\\cZ}  \\sum_{t=1}^{|y|}  \\log\\left({p_{\\Phi_0+\\Delta\\Phi(\\Theta)}(y_{t} | x, y_{<t}})\\right)\n",
    "\\label{eq:ft_add}\n",
    "\\end{align}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8437c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 시스템/유저 메시지 ----------------------------\n",
    "system_msg = (\n",
    "    \"You are a math tutor. Explain in clear, simple English so that a middle-school student can understand. \"\n",
    "    \"Do NOT provide final numeric answers; focus only on interpretation and intuition. \"\n",
    "    \"Keep all symbols exactly as written (same letters, indices i,j, hats, and √); \"\n",
    "    \"do not introduce new symbols; do not expand (a-b)^2; \"\n",
    "    \"do not restate the prompt or echo the equation unless strictly necessary.\"\n",
    ")\n",
    "\n",
    "user_msg = f\"다음 수식을 중학생도 이해할 수 있도록 쉽게 설명합니다.\\n\\n[수식]\\n{EQN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f2d5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Chat 템플릿 적용 -----------------------------------------------------------\n",
    "chat_prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"system\", \"content\": system_msg},\n",
    "     {\"role\": \"user\", \"content\": user_msg}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e813d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 생성 실행(결정적; temperature 미사용 → 경고 없음) ---------------------------\n",
    "gen_kwargs = {\n",
    "    \"max_new_tokens\": 700,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"return_full_text\": False,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "out = generator(chat_prompt, **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be06e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 모델 출력 ===\n",
      "\n",
      "This is the formula you provided:\n",
      "\n",
      "\\[\n",
      "\\max_{\\theta} \\sum{(x,y) \\in \\mathcal{Z}} \\sum_{i=1}^{n} \\log\\big(p_{\\phi_0 + \\delta\\phi(\\theta)}(y_i | x, \\mathbf{y}_{<i})\\big)\n",
      "\\]\n",
      "\n",
      "Let's break it down step by step to make it easier for a middle school student to understand.\n",
      "\n",
      "### Step 1: Understanding the Summation Notation\n",
      "\n",
      "The symbol \\(\\sum\\) means \"sum.\" The expression inside the summation tells us what we are adding up.\n",
      "\n",
      "- \\((x, y) \\in Z\\): This means we are considering pairs of \\(x\\) and \\(y\\) from a set called \\(Z\\).\n",
      "- \\(\\sum_{i = 1}^{N}\\): This means summing over all values of \\(i\\) from 1 to \\(N\\).\n",
      "\n",
      "So, the first part of the formula is:\n",
      "\\[\n",
      "\\sum_{(X,Y) \\in X} \\sum_i \\log\\Bigg(p_{\\Phi_{0} + \\Delta\\Phi (\\Theta)}(Y_i | X, Y_{<i}) \\Bigg)\n",
      "\\]\n",
      "\n",
      "### Step 2: Breaking Down the Inner Summation\n",
      "\n",
      "The inner summation \\(\\sum_i\\) means we are summing over each element \\(i\\) in the sequence \\(Y\\).\n",
      "\n",
      "- \\(Y_i\\): This is the \\(i\\)-th element of the sequence \\(y\\).\n",
      "- \\(X\\): This represents the input data.\n",
      "- \\(Y_{<i}\\): This represents all elements of \\(y\\) before the \\(i\\)th element.\n",
      "\n",
      "So, the inner summation is:\n",
      "\\(\n",
      "\\sum_i \\text{log}\\Bigg(p(Y_i | X, Y_{< i}) \\Big g)\n",
      "\\)\n",
      "\n",
      "### Step 3: Understanding the Logarithm\n",
      "\n",
      "The logarithm function \\(\\log\\) is used to measure the probability of an event occurring. In this context, it measures how likely it is that the \\(i+1\\)th element of \\(y\\), given the previous elements and the current input \\(x\\).\n",
      "\n",
      "### Step 4: Putting It All Together\n",
      "\n",
      "The entire formula is maximizing the sum of these probabilities over all pairs \\((x,y)\\) in the set \\(Z\\). This means we want to find the parameters \\(\\theta\\) that make the overall likelihood of observing the sequence \\(z\\) as high as possible.\n",
      "\n",
      "### Final Interpretation\n",
      "\n",
      "In simpler terms, this formula is trying to find the best parameters \\(\\Theta\\) that maximize the log-likelihood of the observed data \\(z\\). It does this by considering each pair \\((x_i, y_i)\\) in \\(z\\) and calculating the probability of each \\(y_i\\) given the previous \\(y_{<i}, x_i\\), and then summing these probabilities across all pairs.\n",
      "\n",
      "This process helps us determine the most probable sequence of outputs \\(y\\) given the inputs \\(x\\) by adjusting the parameters \\Theta to optimize the model's performance.\n"
     ]
    }
   ],
   "source": [
    "# 7) 결과 출력 -------------------------------------------------------------------\n",
    "print(\"=== 모델 출력 ===\\n\")\n",
    "print(out[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
